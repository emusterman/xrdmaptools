{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import skimage.io as io\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import KDTree, distance_matrix\n",
    "from tqdm import tqdm\n",
    "from itertools import product, combinations\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrdmaptools.geometry.geometry import get_q_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to databrokers...failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emusterma\\AppData\\Local\\anaconda3\\envs\\sXRDMap-py311-1.0\\Lib\\site-packages\\pyopencl\\cache.py:495: CompilerWarning: Non-empty compiler output encountered. Set the environment variable PYOPENCL_COMPILER_OUTPUT=1 to see more.\n",
      "  _create_built_program_from_source_cached(\n"
     ]
    }
   ],
   "source": [
    "%run -i \"C:\\Users\\emusterma\\OneDrive - Brookhaven National Laboratory\\Documents\\Postdoc\\Repositories\\SRX_sXRD_analysis\\xrdmaptools\\io\\hdf_io_rev.py\"\n",
    "%run -i \"C:\\Users\\emusterma\\OneDrive - Brookhaven National Laboratory\\Documents\\Postdoc\\Repositories\\SRX_sXRD_analysis\\xrdmaptools\\XRDData.py\"\n",
    "%run -i \"C:\\Users\\emusterma\\OneDrive - Brookhaven National Laboratory\\Documents\\Postdoc\\Repositories\\SRX_sXRD_analysis\\xrdmaptools\\XRDBaseScan.py\"\n",
    "%run -i \"C:\\Users\\emusterma\\OneDrive - Brookhaven National Laboratory\\Documents\\Postdoc\\Repositories\\SRX_sXRD_analysis\\xrdmaptools\\XRDRockingCurveStack.py\"\n",
    "%run -i \"C:\\Users\\emusterma\\OneDrive - Brookhaven National Laboratory\\Documents\\Postdoc\\Repositories\\SRX_sXRD_analysis\\xrdmaptools\\XRDMap_rev.py\"\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...done!\n",
      "Writing images to hdf...done!\n",
      "WARNING: No energy or wavelength provided.\n",
      "WARNING: No theta provided. Assuming 0 degrees.\n"
     ]
    }
   ],
   "source": [
    "scan_range = '156229-156251'\n",
    "scan_range = '156253-156275'\n",
    "# scan_range = '156277-156299'\n",
    "# scan_range = '156301-156323'\n",
    "# scan_range = '156325-156347'\n",
    "# scan_range = '156349-156371'\n",
    "# scan_range = '156373-156395'\n",
    "# scan_range = '156397-156419'\n",
    "# scan_range = '156421-156443'\n",
    "# scan_range = '156445-156467'\n",
    "\n",
    "\n",
    "filedir = 'E:\\\\Musterman_data\\\\20240610\\\\energy_rc\\\\'\n",
    "filename = f'scan{scan_range}_dexela_energy_rc.tif'\n",
    "\n",
    "rsm = XRDRockingCurveStack.from_image_stack(filename,\n",
    "                                            wd=filedir,\n",
    "                                            scanid=scan_range,\n",
    "                                            save_hdf=True)\n",
    "\n",
    "rsm.load_metadata_from_txt()\n",
    "rsm.load_parameters_from_txt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting detector calibration...\n",
      "Calibration performed under different settings. Adjusting calibration.\n"
     ]
    }
   ],
   "source": [
    "calib_dir = 'E:\\\\Musterman_data\\\\20240610\\\\calibrations\\\\'\n",
    "rsm.set_calibration('scan156160_dexela_calibration.poni', filedir=calib_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcting dark-field...done!\n"
     ]
    }
   ],
   "source": [
    "dark_id = 156203\n",
    "dark_dir = 'E:\\\\Musterman_data\\\\20240610\\\\dark_fields\\\\'\n",
    "dir_mask = [str(dark_id) in d for d in os.listdir(dark_dir)]\n",
    "\n",
    "dark_field = io.imread(f'{dark_dir}{np.array(os.listdir(dark_dir))[dir_mask][0]}').astype(np.float32)\n",
    "rsm.correct_dark_field(dark_field=dark_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing images by i0 scaler...done!\n"
     ]
    }
   ],
   "source": [
    "rsm.normalize_scaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding and correcting image outliers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [00:49<00:00,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Replaced 103281980 outlier pixels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rsm.correct_outliers(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying X-ray polarization correction...done!\n",
      "Applying solid angle correction...done!\n"
     ]
    }
   ],
   "source": [
    "rsm.apply_polarization_correction()\n",
    "rsm.apply_solidangle_correction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating background with Bruckner algorithm.\n",
      "WARNING: No mask could be constructed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [01:07<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing background..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "rsm.estimate_background(method='bruckner', binning=8, min_prominence=0.1)\n",
    "rsm.remove_background()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsm.rescale_images(arr_max=rsm.estimate_saturated_pixel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching images for blobs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [00:59<00:00,  4.03it/s]\n"
     ]
    }
   ],
   "source": [
    "rsm.find_2D_blobs(threshold_method='minimum',\n",
    "                  multiplier=4,\n",
    "                  size=3,\n",
    "                  expansion=5,\n",
    "                  override_rescale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsm.plot_image(contours=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caution: Images not corrected for:\n",
      "\tflat_field\n",
      "\tair_scatter\n",
      "\tpixel_defects\n",
      "\tpixel_distortions\n",
      "\tpolar_calibration\n",
      "\tlorentz\n",
      "\tabsorption\n",
      "Cleaning and updating image information...\n",
      "Diffraction map size is 5.362 GB.\n",
      "Compressing and writing images to disk.\n",
      "This may take a while...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "rsm.finalize_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from hdf file...\n",
      "Loading images from (final_images)...done!\n",
      "Loading reciprocal positions...done!\n",
      "Loading scalers...done!\n",
      "Setting detector calibration...\n",
      "XRDRockingCurveStack loaded!\n"
     ]
    }
   ],
   "source": [
    "scan_range = '156373-156395'\n",
    "filename = f'scan{scan_range}_xrd.h5'\n",
    "filedir = 'E:\\\\Musterman_data\\\\20240610\\\\energy_rc\\\\'\n",
    "\n",
    "rsm = XRDRockingCurveStack.from_hdf(filename,\n",
    "                                    wd=filedir,\n",
    "                                    save_hdf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 1000x1000 with 2 Axes>,\n",
       " <Axes: title={'center': '0'}>,\n",
       " <matplotlib.widgets.Slider at 0x2a7ec195750>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xrdmaptools.plot.stacked import base_slider_plot\n",
    "\n",
    "base_slider_plot(rsm.images.squeeze(), rsm.energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [01:34<00:00,  2.54it/s]\n"
     ]
    }
   ],
   "source": [
    "edges = [[] for _ in range(12)]\n",
    "# qx, qy, qz = [], [], []\n",
    "\n",
    "# Reserve memory; a little faster, maybe\n",
    "q_vectors = np.zeros((np.sum(rsm.blob_masks), 3), dtype=rsm.dtype)\n",
    "# q_vectors[:] = np.nan\n",
    "filled_indices = 0\n",
    "for i, wavelength in tqdm(enumerate(rsm.wavelength), total=rsm.num_images):\n",
    "    q_arr = get_q_vect(rsm.tth_arr,\n",
    "                       rsm.chi_arr,\n",
    "                       wavelength=wavelength,\n",
    "                       degrees=rsm.polar_units == 'deg').astype(rsm.dtype)\n",
    "    \n",
    "    next_indices = np.sum(rsm.blob_masks[i])\n",
    "    \n",
    "    q_vectors[filled_indices : filled_indices + next_indices,\n",
    "              0] = q_arr[0][rsm.blob_masks[i].squeeze()]\n",
    "    q_vectors[filled_indices : filled_indices + next_indices,\n",
    "              1] = q_arr[1][rsm.blob_masks[i].squeeze()]\n",
    "    q_vectors[filled_indices : filled_indices + next_indices,\n",
    "              2] = q_arr[2][rsm.blob_masks[i].squeeze()]\n",
    "\n",
    "    filled_indices += next_indices\n",
    "    \n",
    "    # qx.extend(q_arr[0][rsm.blob_masks[i].squeeze()])\n",
    "    # qy.extend(q_arr[1][rsm.blob_masks[i].squeeze()])\n",
    "    # qz.extend(q_arr[2][rsm.blob_masks[i].squeeze()])\n",
    "\n",
    "    if i == 0:\n",
    "        edges[4] = q_arr[:, 0].T\n",
    "        edges[5] = q_arr[:, -1].T\n",
    "        edges[6] = q_arr[:, :, 0].T\n",
    "        edges[7] = q_arr[:, :, -1].T\n",
    "    elif i == len(rsm.wavelength) - 1:\n",
    "        edges[8] = q_arr[:, 0].T\n",
    "        edges[9] = q_arr[:, -1].T\n",
    "        edges[10] = q_arr[:, :, 0].T\n",
    "        edges[11] = q_arr[:, :, -1].T\n",
    "    else:\n",
    "        edges[0].append(q_arr[:, 0, 0])\n",
    "        edges[1].append(q_arr[:, 0, -1])\n",
    "        edges[2].append(q_arr[:, -1, 0])\n",
    "        edges[3].append(q_arr[:, -1, -1])\n",
    "\n",
    "for i in range(4):\n",
    "    edges[i] = np.asarray(edges[i])\n",
    "\n",
    "# qs = np.asarray([qx, qy, qz]).T # May not need transpose\n",
    "intensity = rsm.images[rsm.blob_masks] # This line alone takes some time\n",
    "\n",
    "min_wavelength, max_wavelength = np.min(rsm.wavelength), np.max(rsm.wavelength)\n",
    "min_tth, max_tth = np.min(rsm.tth_arr), np.max(rsm.tth_arr)\n",
    "min_chi, max_chi = np.min(rsm.chi_arr), np.max(rsm.chi_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrdmaptools.reflections.spot_blob_search_3d import rsm_blob_search, rsm_spot_search\n",
    "# %run -i \"C:\\Users\\emusterma\\OneDrive - Brookhaven National Laboratory\\Documents\\Postdoc\\Repositories\\SRX_sXRD_analysis\\xrdmaptools\\reflections\\spot_blob_search_3d.py\"\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding spots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31916/31916 [00:05<00:00, 6186.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampling data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159584/159584 [00:05<00:00, 29117.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "159584"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_mask = intensity > np.min(intensity) + 0.06 * (np.max(intensity) - np.min(intensity))\n",
    "\n",
    "spot_labels, spots, label_ints = rsm_spot_search(q_vectors[int_mask], intensity[int_mask], nn_dist=0.005, significance=0.1, subsample=5)\n",
    "len(spot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection': '3d'})\n",
    "\n",
    "skip = 500\n",
    "\n",
    "ax.scatter(*q_vectors[int_mask][::skip].T, c=spot_labels[::skip], s=1, alpha=1, cmap='tab20')\n",
    "\n",
    "for edge in edges:\n",
    "    ax.plot(*edge.T, lw=1, c='gray')\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling blob search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490656/490656 [00:11<00:00, 42408.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding blobs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490656/490656 [02:33<00:00, 3195.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampling data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9813119/9813119 [06:14<00:00, 26231.54it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = rsm_blob_search(qs, max_dist=0.05, max_neighbors=5, subsample=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling blob search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 639911/639911 [00:11<00:00, 55980.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding blobs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 639911/639911 [03:53<00:00, 2745.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampling data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6399103/6399103 [03:55<00:00, 27165.97it/s]\n"
     ]
    }
   ],
   "source": [
    "int_mask = intensity > np.min(intensity) + 0.01 * (np.max(intensity) - np.min(intensity))\n",
    "int_labels = rsm_blob_search(qs[int_mask], max_dist=0.05, max_neighbors=5, subsample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection': '3d'})\n",
    "\n",
    "skip = 250\n",
    "\n",
    "ax.scatter(*q_vectors[::skip].T, c=intensity[::skip], s=1, alpha=0.01)\n",
    "\n",
    "for edge in edges:\n",
    "    ax.plot(*edge.T, lw=1, c='gray')\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection': '3d'})\n",
    "\n",
    "skip = 1\n",
    "blob_label = 1\n",
    "another_mask = (labels == blob_label) & int_mask\n",
    "\n",
    "ax.scatter(*q_vectors[another_mask][::skip].T, c=intensity[another_mask][::skip], s=1, alpha=0.1)\n",
    "\n",
    "for edge in edges:\n",
    "    ax.plot(*edge.T, lw=1, c='gray')\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "\n",
    "def map_2_grid(qs, intensity, gridstep=0.005):\n",
    "\n",
    "    # Find bounds\n",
    "    x_min = np.min(qs[:, 0])\n",
    "    x_max = np.max(qs[:, 0])\n",
    "    y_min = np.min(qs[:, 1])\n",
    "    y_max = np.max(qs[:, 1])\n",
    "    z_min = np.min(qs[:, 2])\n",
    "    z_max = np.max(qs[:, 2])\n",
    "\n",
    "    # Generate q-space grid\n",
    "    xx = np.linspace(x_min, x_max, int((x_max - x_min) / gridstep))\n",
    "    yy = np.linspace(y_min, y_max, int((y_max - y_min) / gridstep))\n",
    "    zz = np.linspace(z_min, z_max, int((z_max - z_min) / gridstep))\n",
    "\n",
    "    grid = np.array(np.meshgrid(xx, yy, zz, indexing='ij'))\n",
    "    grid = grid.reshape(3, -1).T\n",
    "\n",
    "    int_grid = griddata(qs, intensity, grid, method='nearest')\n",
    "    #int_grid = int_grid.reshape(yy.shape[0], xx.shape[0], zz.shape[0]).T\n",
    "    int_grid = int_grid.reshape(xx.shape[0], yy.shape[0], zz.shape[0])\n",
    "\n",
    "    return np.array([*np.meshgrid(xx, yy, zz, indexing='ij'), int_grid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, Z, int_grid = map_2_grid(spot_qs[int_mask], spot_ints[int_mask], gridstep=0.00125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "plot_grid = int_grid\n",
    "#plot_grid[plot_grid < 1e-3] = 1e-3\n",
    "#plot_grid = np.log(plot_grid).flatten()\n",
    "data = []\n",
    "\n",
    "data.append(go.Volume(\n",
    "    x=X.flatten(),\n",
    "    y=Y.flatten(),\n",
    "    z=Z.flatten(),\n",
    "    value=plot_grid.flatten(),\n",
    "    isomin=np.min(int_grid) + 2,\n",
    "    isomax=np.max(int_grid) / 2,\n",
    "    opacity=0.1, # needs to be small to see through all surfaces\n",
    "    surface_count=25, # needs to be a large number for good volume rendering\n",
    "    colorscale='viridis'\n",
    "    ))\n",
    "\n",
    "spot_mask = label_ints >= np.min(label_ints) + 0.00 * (np.max(label_ints) - np.min(label_ints))\n",
    "\n",
    "data.append(go.Scatter3d(\n",
    "    x = np.asarray(spots)[spot_mask, 0],\n",
    "    y = np.asarray(spots)[spot_mask, 1],\n",
    "    z = np.asarray(spots)[spot_mask, 2],\n",
    "    mode='markers',\n",
    "    opacity=1,\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color='red'\n",
    "    )\n",
    "))\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "x_range = np.max(X) - np.min(X)\n",
    "y_range = np.max(Y) - np.min(Y)\n",
    "z_range = np.max(Z) - np.min(Z)\n",
    "\n",
    "fig.update_layout(scene_aspectmode='manual',\n",
    "                  scene_aspectratio=dict(x=x_range, y=y_range, z=z_range))\n",
    "\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection': '3d'})\n",
    "\n",
    "skip = 5\n",
    "blob_label = 5\n",
    "int_mask = intensity > np.min(intensity) + 0.05 * (np.max(intensity) - np.min(intensity))\n",
    "another_mask = (labels == blob_label) & int_mask\n",
    "\n",
    "ax.scatter(*qs[another_mask][::skip].T, c=spot_labels[(labels == blob_label)[int_mask]][::skip], s=1, cmap='tab20')\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "blob_label = np.nonzero(blob_ints == sorted(blob_ints, reverse=True)[4])[0][0]\n",
    "int_mask = intensity > np.min(intensity) + 0.05 * (np.max(intensity) - np.min(intensity))\n",
    "another_mask = (labels == blob_label) & int_mask\n",
    "X, Y, Z, int_grid = map_2_grid(qs[another_mask], intensity[another_mask], gridstep=0.0025)\n",
    "\n",
    "data = []\n",
    "\n",
    "data.append(go.Volume(\n",
    "    x=X.flatten(),\n",
    "    y=Y.flatten(),\n",
    "    z=Z.flatten(),\n",
    "    value=int_grid.flatten(),\n",
    "    isomin=np.min(int_grid) + 2,\n",
    "    isomax=np.max(int_grid) / 2,\n",
    "    opacity=0.1, # needs to be small to see through all surfaces\n",
    "    surface_count=25, # needs to be a large number for good volume rendering\n",
    "    colorscale='viridis'\n",
    "    ))\n",
    "\n",
    "x_range = np.max(X) - np.min(X)\n",
    "y_range = np.max(Y) - np.min(Y)\n",
    "z_range = np.max(Z) - np.min(Z)\n",
    "\n",
    "spot_mask = label_ints >= np.min(label_ints) + 0.05 * (np.max(label_ints) - np.min(label_ints))\n",
    "spot_x = np.asarray(spots)[spot_mask, 0]\n",
    "spot_y = np.asarray(spots)[spot_mask, 1]\n",
    "spot_z = np.asarray(spots)[spot_mask, 2]\n",
    "\n",
    "extent_mask = np.all([\n",
    "    np.min(X) < spot_x, spot_x < np.max(X),\n",
    "    np.min(Y) < spot_y, spot_y < np.max(Y),\n",
    "    np.min(Z) < spot_z, spot_z < np.max(Z),\n",
    "], axis=0)\n",
    "\n",
    "data.append(go.Scatter3d(\n",
    "    x = spot_x[extent_mask],\n",
    "    y = spot_y[extent_mask],\n",
    "    z = spot_z[extent_mask],\n",
    "    mode='markers',\n",
    "    opacity=1,\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color='red'\n",
    "    )\n",
    "))\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "fig.update_layout(scene_aspectmode='manual',\n",
    "                  scene_aspectratio=dict(x=x_range, y=y_range, z=z_range))\n",
    "\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n"
     ]
    }
   ],
   "source": [
    "spot_mask = label_ints >= np.min(label_ints) + 0.0001 * (np.max(label_ints) - np.min(label_ints))\n",
    "# sorted_ints = sorted(np.asarray(label_ints)[spot_mask])\n",
    "# sorted_spots = [x for _, x in sorted(zip(np.asarray(label_ints)[spot_mask],\n",
    "#                                          np.asarray(spots)[spot_mask]),\n",
    "#                                          key=lambda pair: pair[0])]\n",
    "print(np.sum(spot_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling blob search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 630/630 [00:00<00:00, 52416.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding blobs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 630/630 [00:00<00:00, 5391.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from xrdmaptools.utilities.utilities import arbitrary_center_of_mass\n",
    "\n",
    "labels = rsm_blob_search(np.asarray(spots)[spot_mask], max_dist=0.25)\n",
    "new_spots = [arbitrary_center_of_mass(np.asarray(label_ints)[spot_mask][labels == label],\n",
    "                                      *np.asarray(spots)[spot_mask][labels == label].T\n",
    "                                      ) for label in np.unique(labels)]\n",
    "print(len(new_spots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection':'3d'})\n",
    "\n",
    "ax.scatter(*np.asarray(spots)[spot_mask].T, s = 1, c=labels, cmap='tab20')\n",
    "\n",
    "q_mins = np.min(np.vstack(edges), axis=0)\n",
    "q_maxs = np.max(np.vstack(edges), axis=0)\n",
    "ax.set_xlim(q_mins[0], q_maxs[0])\n",
    "ax.set_ylim(q_mins[1], q_maxs[1])\n",
    "ax.set_zlim(q_mins[2], q_maxs[2])\n",
    "\n",
    "ax.scatter(*np.asarray(new_spots).T, s=10, c='r')\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrdmaptools.crystal.Phase import Phase\n",
    "cif_dir = '''C:\\\\Users\\\\emusterma\\\\OneDrive - Brookhaven National Laboratory\\\\Documents\\\\Postdoc\\\\Literature\\\\CIF\\\\'''\n",
    "stibnite = Phase.fromCIF(cif_dir + 'AMCSD\\\\Stibnite_0008636.cif')\n",
    "stibnite.energy = 15\n",
    "stibnite.get_hkl_reflections()\n",
    "corundum = Phase.fromCIF(cif_dir + 'AMCSD\\\\Corundum_0009327.cif')\n",
    "corundum.energy = 15\n",
    "corundum.get_hkl_reflections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrdmaptools.crystal.Phase import generate_reciprocal_lattice\n",
    "ref_hkls, ref_qs, ref_fs = generate_reciprocal_lattice(stibnite, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 10\n",
    "min_step = 0.5\n",
    "\n",
    "phi1 = np.arange(0, 180, step)\n",
    "PHI = np.arange(0, 180, step)\n",
    "phi2 = np.arange(0, 180, step)\n",
    "\n",
    "eulers = list(product(phi1, PHI, phi2))\n",
    "full_eulers = []\n",
    "num_spots = []\n",
    "\n",
    "ITERATE = True\n",
    "while ITERATE:\n",
    "    # Evaluate new spots\n",
    "    for euler in tqdm(eulers):\n",
    "        if tuple(euler) not in full_eulers:\n",
    "            R = Rotation.from_euler('xzx', euler, degrees=True)\n",
    "            rot_qs = R.apply(ref_qs)\n",
    "            q_mask = generate_q_mask(rot_qs,\n",
    "                                    (min_tth, max_tth),\n",
    "                                    (min_chi, max_chi),\n",
    "                                    (min_wavelength, max_wavelength),\n",
    "                                    ext=0)\n",
    "            full_eulers.append(tuple(euler))\n",
    "            num_spots.append(np.sum(q_mask))\n",
    "\n",
    "    # raise\n",
    "    \n",
    "    # Find boundaries\n",
    "    edge_eulers = np.asarray(full_eulers)[np.asarray(num_spots) == 1]\n",
    "\n",
    "    new_eulers = []\n",
    "    for euler in edge_eulers:\n",
    "        for first_axis, second_axis in ([0, 1], [0, 2], [1, 2]):\n",
    "            line_mask = ((np.asarray(full_eulers)[:, first_axis] == euler[first_axis])\n",
    "                        & (np.asarray(full_eulers)[:, second_axis] == euler[second_axis]))\n",
    "            line_eulers = np.asarray(full_eulers)[line_mask]\n",
    "            line_mask[np.nonzero(line_mask)[0][np.all(line_eulers == euler, axis=1)][0]] = False\n",
    "            line_eulers = line_eulers[~np.all(line_eulers == euler, axis=1)]\n",
    "            line_diffs = line_eulers - euler\n",
    "\n",
    "            if np.sum(line_diffs < 0) > 0:\n",
    "                idx = np.nonzero(line_diffs < 0)[0][np.argmin(np.abs(line_diffs[line_diffs < 0]))]\n",
    "                if np.asarray(num_spots)[line_mask][idx] == 0:\n",
    "                    new_eulers.append(np.mean([euler, line_eulers[idx]], axis=0))\n",
    "            \n",
    "            if np.sum(line_diffs > 0) > 0:\n",
    "                idx = np.nonzero(line_diffs > 0)[0][np.argmin(np.abs(line_diffs[line_diffs > 0]))]\n",
    "                if np.asarray(num_spots)[line_mask][idx] == 0:\n",
    "                    new_eulers.append(np.mean([euler, line_eulers[idx]], axis=0))\n",
    "            # raise\n",
    "\n",
    "    if len(new_eulers) < 1:\n",
    "        break\n",
    "    else:\n",
    "        eulers = new_eulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find boundaries\n",
    "edge_eulers = np.asarray(full_eulers)[np.asarray(num_spots) == 1]\n",
    "\n",
    "new_eulers = []\n",
    "for euler in edge_eulers:\n",
    "    for first_axis, second_axis in ([0, 1], [0, 2], [1, 2]):\n",
    "        line_mask = ((np.asarray(full_eulers)[:, first_axis] == euler[first_axis])\n",
    "                    & (np.asarray(full_eulers)[:, second_axis] == euler[second_axis]))\n",
    "        line_eulers = np.asarray(full_eulers)[line_mask]\n",
    "        line_mask[np.nonzero(line_mask)[0][np.all(line_eulers == euler, axis=1)][0]] = False\n",
    "        line_eulers = line_eulers[~np.all(line_eulers == euler, axis=1)]\n",
    "        line_diffs = line_eulers - euler\n",
    "\n",
    "        if np.sum(line_diffs < 0) > 0:\n",
    "            idx = np.nonzero(line_diffs < 0)[0][np.argmin(np.abs(line_diffs[line_diffs < 0]))]\n",
    "            if np.asarray(num_spots)[line_mask][idx] == 0:\n",
    "                new_eulers.append(np.mean([euler, line_eulers[idx]], axis=0))\n",
    "        \n",
    "        if np.sum(line_diffs > 0) > 0:\n",
    "            idx = np.nonzero(line_diffs > 0)[0][np.argmin(np.abs(line_diffs[line_diffs > 0]))]\n",
    "            if np.asarray(num_spots)[line_mask][idx] == 0:\n",
    "                new_eulers.append(np.mean([euler, line_eulers[idx]], axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 5\n",
    "min_step = 0.1\n",
    "\n",
    "phi1 = np.arange(0, 90, step)\n",
    "PHI = np.arange(90, 180, step)\n",
    "phi2 = np.arange(0, 90, step)\n",
    "\n",
    "eulers = list(product(phi1, PHI, phi2))\n",
    "full_eulers = []\n",
    "num_spots = []\n",
    "\n",
    "ITERATE = True\n",
    "while ITERATE:\n",
    "\n",
    "    current_num_spots = []\n",
    "    current_eulers = []\n",
    "    # print(f'Step is {step} deg.')\n",
    "    for euler in tqdm(eulers):\n",
    "        if euler not in full_eulers:\n",
    "            R = Rotation.from_euler('xzx', euler, degrees=True)\n",
    "            rot_qs = R.apply(ref_qs)\n",
    "            q_mask = generate_q_mask(rot_qs,\n",
    "                                    (min_tth, max_tth),\n",
    "                                    (min_chi, max_chi),\n",
    "                                    (min_wavelength, max_wavelength),\n",
    "                                    ext=0)\n",
    "            full_eulers.append(euler)\n",
    "            num_spots.append(np.sum(q_mask))\n",
    "            current_eulers.append(euler)\n",
    "            current_num_spots.append(np.sum(q_mask))\n",
    "\n",
    "    if step < min_step:\n",
    "        ITERATE = False\n",
    "        break\n",
    "\n",
    "    new_eulers = []\n",
    "    # Only update the step after all have been found\n",
    "    # print(f'Number of found spots is {len(current_num_spots)}.')\n",
    "    # print(f'Number of found spots equal to 1 is {np.sum(np.asarray(current_num_spots) == 1)}.')\n",
    "    if len(current_num_spots) == 0:\n",
    "        step /= 2\n",
    "        for euler in np.asarray(full_eulers)[np.asarray(num_spots) == 1]:\n",
    "            new_phi1 = np.array([euler[0] - step, euler[0], euler[0] + step])\n",
    "            new_phi1 = new_phi1[(new_phi1 >= 0) & (new_phi1 < 180)]\n",
    "            new_PHI = np.array([euler[1] - step, euler[1], euler[1] + step])\n",
    "            new_PHI = new_PHI[(new_PHI >= 0) & (new_PHI < 180)]\n",
    "            new_phi2 = np.array([euler[2] - step, euler[2], euler[2] + step])\n",
    "            new_phi2 = new_phi2[(new_phi2 >= 0) & (new_phi2 < 180)]\n",
    "            extra_eulers = list(product(new_phi1, new_PHI, new_phi2))\n",
    "            new_eulers.extend(extra_eulers)\n",
    "    else:\n",
    "        for euler in np.asarray(current_eulers)[np.asarray(current_num_spots) == 1]:\n",
    "            new_phi1 = np.array([euler[0] - step, euler[0], euler[0] + step])\n",
    "            new_phi1 = new_phi1[(new_phi1 >= 0) & (new_phi1 < 180)]\n",
    "            new_PHI = np.array([euler[1] - step, euler[1], euler[1] + step])\n",
    "            new_PHI = new_PHI[(new_PHI >= 0) & (new_PHI < 180)]\n",
    "            new_phi2 = np.array([euler[2] - step, euler[2], euler[2] + step])\n",
    "            new_phi2 = new_phi2[(new_phi2 >= 0) & (new_phi2 < 180)]\n",
    "            extra_eulers = list(product(new_phi1, new_PHI, new_phi2))\n",
    "            new_eulers.extend(extra_eulers)\n",
    "    \n",
    "    eulers = new_eulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection':'3d'})\n",
    "\n",
    "mask = np.asarray(num_spots) < 2\n",
    "\n",
    "ax.scatter(*np.asarray(full_eulers)[mask].T, c=np.asarray(num_spots)[mask], s=1, alpha=1)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel('phi1')\n",
    "ax.set_ylabel('PHI')\n",
    "ax.set_zlabel('phi2')\n",
    "\n",
    "# ax.set_xlim(0, 90)\n",
    "# ax.set_ylim(90, 180)\n",
    "# ax.set_zlim(0, 90)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [07:24<00:00, 450.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.transform import Rotation\n",
    "# step = 2.5\n",
    "\n",
    "# phi1 = np.arange(0, 90, step)\n",
    "# PHI = np.arange(90, 180, step)\n",
    "# phi2 = np.arange(0, 90, step)\n",
    "\n",
    "# eulers = list(product(phi1, PHI, phi2))\n",
    "\n",
    "num = 200000\n",
    "\n",
    "phi1 = np.random.rand(num) * 360\n",
    "PHI = np.random.rand(num) * 180\n",
    "phi2 = np.random.rand(num) * 360\n",
    "eulers = np.asarray([phi1, PHI, phi2]).T\n",
    "\n",
    "full_eulers = []\n",
    "num_spots = []\n",
    "# print(f'Step is {step} deg.')\n",
    "for euler in tqdm(eulers):\n",
    "    if True or euler not in full_eulers:\n",
    "        R = Rotation.from_euler('xzx', euler, degrees=True)\n",
    "        rot_qs = R.apply(ref_qs)\n",
    "        q_mask = generate_q_mask(rot_qs,\n",
    "                                (min_tth, max_tth),\n",
    "                                (min_chi, max_chi),\n",
    "                                (min_wavelength, max_wavelength),\n",
    "                                ext=0)\n",
    "        full_eulers.append(euler)\n",
    "        num_spots.append(np.sum(q_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrdmaptools.crystal.orientation import g_func\n",
    "fig, ax = plt.subplots(1, 3, subplot_kw={'projection':'polar'})\n",
    "\n",
    "triangle = True\n",
    "ipf = True\n",
    "full_eulers = np.asarray(full_eulers)\n",
    "num_spots = np.asarray(num_spots)\n",
    "\n",
    "mask = num_spots < 200\n",
    "\n",
    "if ipf:\n",
    "    r, theta, ipole, colors = ipole_fig(g_func(*np.asarray(full_eulers[mask]).T), [1, 0, 0], triangle=triangle)\n",
    "else:\n",
    "    r, theta, ipole = pole_fig(g_func(*np.asarray(full_eulers[mask]).T), [1, 0, 0])\n",
    "pole_plot(r, theta, ipole, c=num_spots[mask], fig=fig, ax=ax[0], triangle=triangle, cmap='viridis', s=5, colorbar=True)\n",
    "\n",
    "if ipf :\n",
    "    r, theta, ipole, colors = ipole_fig(g_func(*np.asarray(full_eulers[mask]).T), [0, 1, 0], triangle=triangle)\n",
    "else:\n",
    "    r, theta, ipole = pole_fig(g_func(*np.asarray(full_eulers[mask]).T), [0, 1, 0])\n",
    "pole_plot(r, theta, ipole, c=num_spots[mask], fig=fig, ax=ax[1], triangle=triangle, cmap='viridis', s=5, colorbar=True)\n",
    "\n",
    "if ipf:\n",
    "    r, theta, ipole, colors = ipole_fig(g_func(*np.asarray(full_eulers[mask]).T), [0, 0, 1], triangle=triangle)\n",
    "else:\n",
    "    r, theta, ipole = pole_fig(g_func(*np.asarray(full_eulers[mask]).T), [0, 0, 1])\n",
    "pole_plot(r, theta, ipole, c=num_spots[mask], fig=fig, ax=ax[2], triangle=triangle, cmap='viridis', s=5, colorbar=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipole_fig(g, ipole, IQ=None, CI=None, FIT=None, norm_iq=[], ci=[], fit=[], triangle=False, transparent=False):\n",
    "\n",
    "    '''\n",
    "    g           (list)  List of orienation matrices from g_func of Euler angles\n",
    "    ipole       (list)  Sample axis about which pole figure is referenced (e.g., [0,0,1] is surface normal (ND))\n",
    "    IQ          (float) Cut-off fraction of normalized image quality (IQ) values to use. (e.g., 0.4 uses top 60% of values)\n",
    "    CI          (float) Cut-off value of confidence index (CI) values to use. (e.g., 0.1 uses all higher)\n",
    "    FIT         (float) Cut-off value of fit values to use. (e.g., 2 uses all lower fits)\n",
    "    norm_iq     (list)  Normalized image quality values per pixel\n",
    "    ci          (list)  Confidence index values per pixel\n",
    "    fit         (list)  Fit values per pixel\n",
    "    triangle    (bool)  Use unit triangle or full hemisphere (points are doubled if false)\n",
    "    transparent (bool)  Sets pixels to transparent for mapping overlays\n",
    "    '''\n",
    "\n",
    "    # Check to make sure filters have values to parse\n",
    "    if (None != (IQ or CI or FIT)) and (0 == (len(norm_iq) or len(ci) or len(fit))):\n",
    "        raise ValueError('You are trying to filter by IQ, CI, or Fit without defining these values!')\n",
    "    \n",
    "    colors, r, theta = [], [], []\n",
    "    for i in range(len(g)):\n",
    "        \n",
    "        # Take only part of the orientation matrix\n",
    "        V = np.dot(g[i], ipole) # order is g, then ipole\n",
    "\n",
    "        # Determine pixel color according to unit triangle\n",
    "        R, G, B = 0, 0, 0\n",
    "        base = 30 / 255 #all pixels are a bit brighter\n",
    "        R=np.abs(V[2]) + base # referenced to crystallographic axes, but should be able to reference any axis\n",
    "        G=np.abs(V[0]) + base\n",
    "        B=np.abs(V[1]) + base\n",
    "\n",
    "        # Normalize and brighten colors\n",
    "        max_c = np.max([R,G,B])\n",
    "        R = R / max_c\n",
    "        G = G / max_c\n",
    "        B = B / max_c\n",
    "        \n",
    "        # Setting pixel transparency if called\n",
    "        A=1\n",
    "        if transparent:\n",
    "            if IQ != None and norm_iq[i] < IQ: A = 0\n",
    "            if CI != None and ci[i] < CI: A = 0\n",
    "            if FIT != None and fit[i] > FIT: A = 0\n",
    "        \n",
    "        # Black out unused pixels\n",
    "        if IQ != None and norm_iq[i] < IQ: R,G,B = 0, 0, 0\n",
    "        if CI != None and ci[i] < CI: R,G,B = 0, 0, 0\n",
    "        if FIT != None and fit[i] > FIT: R,G,B = 0, 0, 0\n",
    "\n",
    "        colors.append([R, G, B, A]) #must be as big as x-y scan, so no reduction in size\n",
    "        \n",
    "        # Determine polar coordinates using stereographic projection\n",
    "        # Only use the points that pass filters\n",
    "        if (IQ == None or norm_iq[i] > IQ) and (CI == None or ci[i] > CI) and (FIT == None or fit[i] < FIT):\n",
    "            r_i = (1 - np.abs(V[2]) / (1 + np.abs(V[2]))) * np.sqrt((V[1] * V[1]) + (V[0] * V[0]))\n",
    "            if triangle:\n",
    "                theta_i = np.abs(np.arctan(V[1] / V[0]))\n",
    "                r.append(r_i)\n",
    "                theta.append(theta_i)\n",
    "            else:\n",
    "                theta_i = np.arctan(V[1] / V[0])\n",
    "                if (V[0] < 0):\n",
    "                    theta_i += np.pi\n",
    "                if (V[2] < 0):\n",
    "                    theta_i = np.pi - theta_i\n",
    "                #doubles length of output to account for mirror symmetry of Sb2S3\n",
    "                r.append(r_i), r.append(r_i)\n",
    "                theta.append(theta_i), theta.append(theta_i + np.pi)\n",
    "\n",
    "    # colors will always remain the same size as input\n",
    "    # r and theta will reduce based on filters\n",
    "    r = np.asarray(r)\n",
    "    theta = np.asarray(theta)\n",
    "    colors = np.asarray(colors)\n",
    "    return r, theta, ipole, colors\n",
    "\n",
    "def pole_fig(g, pole, IQ=None, CI=None, FIT=None, norm_iq=[], ci=[], fit=[]):\n",
    "\n",
    "    '''\n",
    "    g       (list)  List of orienation matrices from g_func of Euler angles\n",
    "    pole    (list)  Crystallographic axis about which pole figure is referenced (e.g., [1,0,0] is a-axis)\n",
    "    IQ      (float) Cut-off fraction of normalized image quality (IQ) values to use. (e.g., 0.4 uses top 60% of values)\n",
    "    CI      (float) Cut-off value of confidence index (CI) values to use. (e.g., 0.1 uses all higher)\n",
    "    FIT     (float) Cut-off value of fit values to use. (e.g., 2 uses all lower fits)\n",
    "    norm_iq (list)  Normalized image quality values per pixel\n",
    "    ci      (list)  Confidence index values per pixel\n",
    "    fit     (list)  Fit values per pixel\n",
    "    '''\n",
    "\n",
    "    # Check to make sure filters have values to parse\n",
    "    if (None != (IQ or CI or FIT)) and (0 == (len(norm_iq) or len(ci) or len(fit))):\n",
    "        raise ValueError('You are trying to filter by IQ, CI, or Fit without defining these values!')\n",
    "    \n",
    "    # Determine polar coordinates using stereographic projection\n",
    "    r, theta = [],[]\n",
    "    for i in range(len(g)):\n",
    "        # Only use the points that pass filters\n",
    "        if (IQ == None or norm_iq[i] > IQ) and (CI == None or ci[i] > CI) and (FIT == None or fit[i] < FIT):\n",
    "            V = np.dot(pole, g[i])\n",
    "            theta_i = -np.arctan(V[0] / V[1])\n",
    "            if (V[1] < 0 and V[2] < 0) or (V[1] > 0 and V[2] > 0):\n",
    "                theta_i += np.pi\n",
    "            r_i = (1 - np.abs(V[2]) / (1 + np.abs(V[2]))) * np.sqrt((V[0] * V[0]) + (V[1] * V[1]))\n",
    "            r.append(r_i)\n",
    "            theta.append(theta_i)\n",
    "\n",
    "    r = np.asarray(r)\n",
    "    theta = np.asarray(theta)\n",
    "    return r, theta, pole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pole_plot(r, theta, pole, c='k', alpha=1, cmap='Spectral_r', s=0.5,\n",
    "              vmin=None, vmax=None, ax=None, fig=None, \n",
    "              colorbar=False, triangle=False, full_pole = False,\n",
    "              marker='.'):\n",
    "\n",
    "    '''\n",
    "    r           (list)      Radius values from figure functions\n",
    "    theta       (list)      Theta values from figure functions\n",
    "    pole        (list)      Crystallographic pole to reference\n",
    "    c           (list)      Defualt string or list of custom colors\n",
    "    alpha       (float)     Transparency of points. Useful with dense data\n",
    "    cmap        (string)    Color map for custom point colors in c. Defualt is Spectral_r\n",
    "    s           (float)     Defualt point size. Useful with dense data\n",
    "    vmin        (float)     Minimum value for colorscale\n",
    "    vmax        (float)     Maximum value for colorscale\n",
    "    ax          (object)    Pyplot axis for plotting\n",
    "    fig         (object)    Pypolot figure for plotting\n",
    "    colorbar    (bool)      Adds color bar when true\n",
    "    triangle    (bool)      Plots on unit triangle when true. Should only be used with IPF  \n",
    "    '''\n",
    "\n",
    "    # Checking pyplot inputs\n",
    "    if fig == None:\n",
    "        raise ValueError('You need to define a figure!')\n",
    "    if ax is None:\n",
    "        ax = plt.gca(projection='polar')\n",
    "    \n",
    "    if len(pole) == 3:\n",
    "        orig_pole = pole\n",
    "    elif len(pole) == 4:\n",
    "        orig_pole = pole\n",
    "        pole = [orig_pole[0], orig_pole[1], orig_pole[3]]\n",
    "    else:\n",
    "        raise AttributeError(f\"Pole input should have len 3 or 4. {len(pole)} were given.\")\n",
    "\n",
    "    # Plotting!\n",
    "    ax.set_title(\"\".join(str(e) for e in orig_pole), y=1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    if triangle:\n",
    "        ax.set_xlim(0, np.pi / 2)\n",
    "    #elif full_pole and type(c) != str:\n",
    "    elif type(c) != str and len(r) == 2 * len(c):\n",
    "        c = np.asarray([item for sub in c for item in [sub] * 2]) #Shows both axes for full hemisphere\n",
    "    im = ax.scatter(theta, r, s=s, alpha=alpha, c=c, cmap=cmap, vmin=vmin, vmax=vmax, marker=marker, edgecolors='none')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if colorbar:\n",
    "        cbar = fig.colorbar(im, ax=ax, shrink=0.6, orientation='vertical', pad=0.04)\n",
    "        cbar.solids.set(alpha=1) # avoids transparency issues\n",
    "\n",
    "    return ax, im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_angles = [[10, 20, 0],\n",
    "               [10, 25, 0],\n",
    "               [10, 15, 0]]\n",
    "test_spots = []\n",
    "\n",
    "for euler_angles in test_angles:\n",
    "    R = Rotation.from_euler('xzx', euler_angles, degrees=True)\n",
    "    rot_qs = R.apply(ref_qs)\n",
    "    q_mask = generate_q_mask(rot_qs,\n",
    "                            (min_tth, max_tth),\n",
    "                            (min_chi, max_chi),\n",
    "                            (min_wavelength, max_wavelength),\n",
    "                            ext=0)\n",
    "    test_spots.append(rot_qs[q_mask])\n",
    "\n",
    "    break\n",
    "\n",
    "test_spots = np.vstack(test_spots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1730/1730 [00:26<00:00, 64.13it/s] \n"
     ]
    }
   ],
   "source": [
    "from xrdmaptools.crystal.Phase import generate_reciprocal_lattice\n",
    "from itertools import combinations\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "spot_qs = np.asarray(spots)[spot_mask]\n",
    "#spot_ints = np.asarray(label_ints)[spot_mask]\n",
    "\n",
    "spot_qs = np.asarray(new_spots)\n",
    "#spot_qs = np.asarray(corr_spot_qs)\n",
    "# spot_qs = np.asarray([test_spots[6], test_spots[9]])\n",
    "\n",
    "phase = stibnite\n",
    "near_q = 0.1\n",
    "near_angle = 2\n",
    "\n",
    "# near_q = 0.025\n",
    "# near_angle = 1\n",
    "    \n",
    "spot_q_mags = np.linalg.norm(spot_qs, axis=1)\n",
    "max_q = np.max(spot_q_mags)\n",
    "\n",
    "# Combine these at some point...\n",
    "stibnite.get_hkl_reflections()\n",
    "ref_hkls, ref_qs, ref_fs = generate_reciprocal_lattice(stibnite, 1.15 * max_q) # 15% window\n",
    "# ref_qs = ref_qs @ (np.eye(3) - eij_full)\n",
    "ref_q_mags = np.linalg.norm(ref_qs, axis=1)\n",
    "\n",
    "# Minimum step size in q-space.\n",
    "min_q = np.min(np.linalg.norm(phase.Q([[1, 0, 0], [0, 1, 0], [0, 0, 1]]), axis=0))\n",
    "if near_q > min_q * 0.85:\n",
    "    raise ValueError('Near_q threshold is greater 85% of minimum lattice spacing. This seems unwise...')\n",
    "\n",
    "# Find difference between measured and calculated q magnitudes\n",
    "mag_diff_arr = np.abs(spot_q_mags[:, np.newaxis]\n",
    "                      - ref_q_mags[np.newaxis, :])\n",
    "\n",
    "# Eliminate any reflections outside phase-allowed spots\n",
    "phase_mask = np.any(mag_diff_arr < near_q, axis=1)\n",
    "mag_diff_arr = mag_diff_arr[phase_mask]\n",
    "spot_qs = spot_qs[phase_mask]\n",
    "spot_q_mags = spot_q_mags[phase_mask]\n",
    "#spot_ints = spot_ints[phase_mask]\n",
    "\n",
    "# Generate all pairs of spots which are crystallographically feasible\n",
    "spot_pair_indices = list(combinations(range(len(spot_qs)), 2))\n",
    "#spot_diff_arr = np.abs(spot_q_mags[:, np.newaxis]\n",
    "#                       - spot_q_mags[np.newaxis, :])\n",
    "spot_pair_dist = distance_matrix(spot_qs, spot_qs)\n",
    "allowed_pairs = [spot_pair_dist[tuple(indices)] > min_q * 0.85 for indices in spot_pair_indices]\n",
    "#allowed_pairs = [spot_pair_dist[indices] > min_q * 0.85 for indices in spot_pair_indices]\n",
    "spot_pair_indices = np.asarray(spot_pair_indices)[allowed_pairs]\n",
    "\n",
    "# Determine all angles\n",
    "spot_angles = multi_vector_angles(spot_qs, spot_qs, degrees=True)\n",
    "ref_angles = multi_vector_angles(ref_qs, ref_qs, degrees=True)\n",
    "\n",
    "valid_pairs, valid_combos = [], []\n",
    "for pair in tqdm(spot_pair_indices):\n",
    "    ref_combos = list(product(*[np.nonzero(mag_diff_arr[i] < near_q)[0] for i in pair]))\n",
    "\n",
    "    angle_mask = [np.abs(spot_angles[tuple(pair)] - ref_angles[tuple(combo)]) < near_angle for combo in ref_combos]\n",
    "    doublet_mask = [combo[0] != combo[1] for combo in ref_combos]\n",
    "\n",
    "    ref_combos = np.asarray(ref_combos)[np.array(angle_mask) & np.array(doublet_mask)]\n",
    "    \n",
    "    if len(ref_combos) > 0:\n",
    "        valid_pairs.append(tuple(pair))\n",
    "        valid_combos.append([tuple(combo) for combo in ref_combos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120348, 60)\n"
     ]
    }
   ],
   "source": [
    "expanded_pair = [np.nan,] * len(spot_qs)\n",
    "expanded_pair_list = []\n",
    "for pair, combos in zip(valid_pairs, valid_combos):\n",
    "    for combo in combos:\n",
    "        expanded_pair_i = expanded_pair.copy()\n",
    "        expanded_pair_i[pair[0]] = combo[0]\n",
    "        expanded_pair_i[pair[1]] = combo[1]\n",
    "        expanded_pair_list.append(expanded_pair_i)\n",
    "        \n",
    "expanded_pair_list = np.asarray(expanded_pair_list)\n",
    "print(expanded_pair_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [00:00<00:00, 1894.00it/s]\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection':'3d'})\n",
    "\n",
    "ax.scatter(*np.asarray(spot_qs).T, s = 1, c='r')\n",
    "\n",
    "skip = np.round(len(expanded_pair_list) / 1000, 0).astype(int)\n",
    "\n",
    "for idx in tqdm(range(len(expanded_pair_list[::skip]))):\n",
    "    ax.plot(*spot_qs[~np.isnan(expanded_pair_list[::skip][idx])].T, c='k', alpha=0.01, lw=1)\n",
    "\n",
    "q_mins = np.min(np.vstack(edges), axis=0)\n",
    "q_maxs = np.max(np.vstack(edges), axis=0)\n",
    "ax.set_xlim(q_mins[0], q_maxs[0])\n",
    "ax.set_ylim(q_mins[1], q_maxs[1])\n",
    "ax.set_zlim(q_mins[2], q_maxs[2])\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_combine(*connections):\n",
    "\n",
    "    connections = np.asarray(connections)\n",
    "    if np.any(np.sum(~np.isnan(connections), axis=0) > 1):\n",
    "        raise RuntimeError('Overwritten connections!')\n",
    "\n",
    "    base_connection = np.asarray([np.nan,] * len(connections[0]))\n",
    "\n",
    "    for connection in connections:\n",
    "        base_connection[~np.isnan(connection)] = connection[~np.isnan(connection)]\n",
    "\n",
    "    return base_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_next_connections(full_pairs,\n",
    "                           partial_connections,\n",
    "                           common_full,\n",
    "                           common_partial=None,\n",
    "                           ):\n",
    "    \n",
    "    full_pairs = np.asarray(full_pairs)\n",
    "    partial_connections = np.asarray(partial_connections)\n",
    "    \n",
    "    # Must have at least two partials to advance connection rank\n",
    "    if len(partial_connections) < 2:\n",
    "        return [], []\n",
    "    \n",
    "    common_indices = np.nonzero(~np.isnan(common_full))[0]\n",
    "    common_vals = common_full[common_indices]\n",
    "\n",
    "    if common_partial is not None:\n",
    "        common_index = np.nonzero(~np.isnan(common_partial))[0][0]\n",
    "        common_val = common_partial[common_index]\n",
    "        common_mask = full_pairs[:, common_index] == common_val\n",
    "    else:\n",
    "        common_mask = [True, ] * len(full_pairs)\n",
    "    \n",
    "    next_partials = []\n",
    "    valid_connections = []\n",
    "    for i in range(len(partial_connections)):\n",
    "        partial = partial_connections[i]\n",
    "        part_index = np.nonzero(~np.isnan(partial))[0][0]\n",
    "        part_val = partial[part_index]\n",
    "\n",
    "        # Ignore indexing repeated spots or references reflections\n",
    "        if (part_index in common_indices\n",
    "            or part_val in common_vals):\n",
    "            continue\n",
    "            \n",
    "        next_conn_mask = full_pairs[:, part_index] == part_val\n",
    "        \n",
    "        if np.sum(common_mask & next_conn_mask) > 0:\n",
    "            next_partials.append(partial)\n",
    "            valid_connections.append(nan_combine(common_full, partial))\n",
    "\n",
    "    return next_partials, valid_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining all orientations from valid pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120348/120348 [00:12<00:00, 9580.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing symmetrically equivalent pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120348/120348 [00:05<00:00, 22210.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17663"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.transform import Rotation\n",
    "from xrdmaptools.geometry.geometry import q_2_polar\n",
    "\n",
    "def get_rmse(spots0, spots1):\n",
    "    rmse = np.mean([np.sqrt(np.sum([(p - q)**2 for p, q in zip(v1, v2)]))\n",
    "                    for v1, v2 in zip(spots0, spots1)])\n",
    "    return rmse\n",
    "\n",
    "def fit_orientation_index(connection,\n",
    "                          spot_qs,\n",
    "                          ref_qs):\n",
    "    fit_spot_indices = np.nonzero(~np.isnan(connection))\n",
    "    fit_spot_qs = spot_qs[fit_spot_indices]\n",
    "\n",
    "    fit_ref_indices = connection[fit_spot_indices].astype(int)\n",
    "    fit_ref_qs = np.asarray(ref_qs)[fit_ref_indices]\n",
    "\n",
    "    fit_orientation, fit_rssd = Rotation.align_vectors(fit_ref_qs, fit_spot_qs)\n",
    "\n",
    "    rmse = get_rmse(fit_ref_qs,\n",
    "                    fit_orientation.apply(fit_spot_qs, inverse=False))\n",
    "\n",
    "    return fit_orientation, rmse\n",
    "\n",
    "print('Determining all orientations from valid pairs...')\n",
    "pair_orientations = []\n",
    "pair_mis_mag = []\n",
    "pair_rmse = []\n",
    "for pair_i in tqdm(range(len(expanded_pair_list))):\n",
    "    pair_ref_hkls = [ref_hkls[int(ind)] for ind\n",
    "                    in expanded_pair_list[pair_i][~np.isnan(expanded_pair_list[pair_i])]]\n",
    "    pair_ref_qs = [ref_qs[int(ind)] for ind\n",
    "                   in expanded_pair_list[pair_i][~np.isnan(expanded_pair_list[pair_i])]]\n",
    "    pair_spot_qs = spot_qs[np.nonzero(~np.isnan(expanded_pair_list[0]))]\n",
    "\n",
    "    # Check for colinearity; 3D orientation cannot be determined\n",
    "    pair_divs = np.array(pair_ref_hkls[0]) / np.array(pair_ref_hkls[1])\n",
    "    if len(np.unique(pair_divs[~np.isnan(pair_divs)])) < 2:\n",
    "        pair_orientations.append(np.nan) # assume validity\n",
    "        pair_rmse.append(np.nan)\n",
    "        pair_mis_mag.append(np.nan)\n",
    "        continue\n",
    "    \n",
    "    orientation, rmse = fit_orientation_index(expanded_pair_list[pair_i],\n",
    "                                              spot_qs,\n",
    "                                              ref_qs)\n",
    "\n",
    "    pair_orientations.append(orientation)\n",
    "    pair_mis_mag.append(np.degrees(orientation.magnitude()))\n",
    "\n",
    "    pair_rmse.append(rmse)\n",
    "\n",
    "pair_orientations = np.asarray(pair_orientations)\n",
    "pair_mis_mag = np.asarray(pair_mis_mag)\n",
    "pair_rmse = np.asarray(pair_rmse)\n",
    "\n",
    "print('Reducing symmetrically equivalent pairs...')\n",
    "eval_pair_mask = np.array([True,] * len(expanded_pair_list))\n",
    "keep_pair_mask = eval_pair_mask.copy()\n",
    "min_wavelength, max_wavelength = np.min(rsm.wavelength), np.max(rsm.wavelength)\n",
    "min_tth, max_tth = np.min(rsm.tth_arr), np.max(rsm.tth_arr)\n",
    "min_chi, max_chi = np.min(rsm.chi_arr), np.max(rsm.chi_arr)\n",
    "for pair_i in tqdm(range(len(expanded_pair_list))):\n",
    "\n",
    "    if not eval_pair_mask[pair_i]:\n",
    "        continue\n",
    "    \n",
    "    # Cannot symmetrically reduce orientations that cannot be determined\n",
    "    if np.isnan(pair_rmse[pair_i]):\n",
    "        eval_pair_mask[pair_i] = False\n",
    "        continue\n",
    "    \n",
    "    # TESTING FEATURE\n",
    "    # Discard poorly fitting pairs\n",
    "    if pair_rmse[pair_i] > min_q:\n",
    "        eval_pair_mask[pair_i] = False\n",
    "        keep_pair_mask[pair_i] = False\n",
    "        print('Horrible fitting')\n",
    "        continue\n",
    "\n",
    "    # Test to make sure all points are in probed volume\n",
    "    IN_SCAN_RANGE = True\n",
    "    pair_ref_qs = ref_qs[expanded_pair_list[pair_i][np.nonzero(~np.isnan(expanded_pair_list[pair_i]))[0]].astype(int)]\n",
    "    rot_qs = pair_ref_qs @ pair_orientations[pair_i].as_matrix()\n",
    "    tth, chi, wavelength = q_2_polar(rot_qs, degrees=True)\n",
    "    tth_mask = np.any([tth < min_tth * 0.85,\n",
    "                       tth > max_tth * 1.15],\n",
    "                       axis=0)\n",
    "    chi_mask = np.any([chi < min_chi * 0.85,\n",
    "                       chi > max_chi * 1.15],\n",
    "                       axis=0)\n",
    "    wavelength_mask = np.any([wavelength < min_wavelength * 0.85,\n",
    "                              wavelength > max_wavelength * 1.15],\n",
    "                              axis=0)\n",
    "    \n",
    "    if np.any([tth_mask, chi_mask, wavelength_mask]):\n",
    "        IN_SCAN_RANGE = False\n",
    "        #IN_SCAN_RANGE = True\n",
    "\n",
    "    # def trunc(values, decs=0):\n",
    "    #     return np.trunc(values * 10**decs) / (10**decs)\n",
    "\n",
    "    # similar_pair_mask = trunc(pair_rmse, 13) == trunc(pair_rmse[pair_i], 13)\n",
    "    similar_pair_mask = np.round(pair_rmse, 10) == np.round(pair_rmse[pair_i], 10)\n",
    "    #sym_pairs = expanded_pair_list[similar_pair_mask]\n",
    "    eval_pair_mask[similar_pair_mask] = False\n",
    "    keep_pair_mask[similar_pair_mask] = False\n",
    "    \n",
    "    if IN_SCAN_RANGE and np.sum(similar_pair_mask) > 1:\n",
    "        # most_positive_index = np.argmax([np.sign(np.asarray(ref_hkls)[pair[np.nonzero(~np.isnan(pair))[0]].astype(int)]).sum()\n",
    "        #                                 for pair in sym_pairs])\n",
    "        # most_positive_index = np.sign(np.asarray(ref_hkls)[sym_pairs[np.nonzero(~np.isnan(sym_pairs))].astype(int)].reshape(-1, 2, 3)).sum(axis=(1, 2)).argmax()\n",
    "\n",
    "        min_mis_mag = np.min(pair_mis_mag[similar_pair_mask])\n",
    "        mis_ind = np.nonzero(pair_mis_mag[similar_pair_mask] < min_mis_mag + near_angle)[0] # some wiggle room\n",
    "\n",
    "        keep_pair_mask[np.nonzero(similar_pair_mask)[0][mis_ind]] = True\n",
    "\n",
    "# pair_orientations = pair_orientations[keep_pair_mask]\n",
    "# pair_mis_mag = pair_mis_mag[keep_pair_mask]\n",
    "# pair_rmse = pair_rmse[keep_pair_mask]\n",
    "np.sum(keep_pair_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quicker cast and search from set of valid pairs\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def generate_q_mask(qs,\n",
    "                    tth_ext,\n",
    "                    chi_ext,\n",
    "                    wavelength_ext,\n",
    "                    q_ext,\n",
    "                    ext=0.15,\n",
    "                    degrees=False):\n",
    "    \n",
    "    # Check extent parameters\n",
    "    for param in [tth_ext, chi_ext, wavelength_ext]:\n",
    "        if len(param) != 2:\n",
    "            raise ValueError('Input extents must be of length 2.')\n",
    "        if param[0] > param[1]:\n",
    "            raise ValueError('Input extents must be (minimum, maximum)')\n",
    "        \n",
    "    # Check qs shape\n",
    "\n",
    "    q_ext_mask = np.all([\n",
    "        np.all([qs[:, 0] > q_ext[0][0] * (1 - ext),\n",
    "                qs[:, 0] < q_ext[1][0] * (1 + ext)], axis=0),\n",
    "        np.all([qs[:, 1] > q_ext[0][1] * (1 - ext),\n",
    "                qs[:, 1] < q_ext[1][1] * (1 + ext)], axis=0),\n",
    "        np.all([qs[:, 2] > q_ext[0][2] * (1 - ext),\n",
    "                qs[:, 2] < q_ext[1][2] * (1 + ext)], axis=0),\n",
    "    ], axis=0)\n",
    "    \n",
    "    tth, chi, wavelength = q_2_polar(qs, degrees=degrees)\n",
    "\n",
    "    tth_mask = np.any([tth < tth_ext[0] * (1 - ext),\n",
    "                       tth > tth_ext[1] * (1 + ext)],\n",
    "                       axis=0)\n",
    "    chi_mask = np.any([chi < chi_ext[0] * (1 - ext),\n",
    "                       chi > chi_ext[1] * (1 + ext)],\n",
    "                       axis=0)\n",
    "    wavelength_mask = np.any([wavelength < wavelength_ext[0] * (1 - ext),\n",
    "                              wavelength > wavelength_ext[1] * (1 + ext)],\n",
    "                              axis=0)\n",
    "\n",
    "    # q_mask = ~(tth_mask | chi_mask | wavelength_mask)\n",
    "    q_mask = q_ext_mask & ~(tth_mask | chi_mask | wavelength_mask)\n",
    "\n",
    "    return q_mask\n",
    "\n",
    "\n",
    "# When we don't know, we through higher order polynomials\n",
    "# at it until it works\n",
    "def poly6(x, a, b, c, d, e, f, g):\n",
    "    return a * x**6 + b * x**5 + c * x**4 + d * x**3 + e * x**2 + f * x + g\n",
    "\n",
    "chi_upr_popt, _ = curve_fit(poly6, rsm.tth_arr[0], rsm.chi_arr[0])\n",
    "chi_lwr_popt, _ = curve_fit(poly6, rsm.tth_arr[-1], rsm.chi_arr[-1])\n",
    "tth_lwr_popt, _ = curve_fit(poly6, rsm.chi_arr[:, 0], rsm.tth_arr[:, 0])\n",
    "tth_upr_popt, _ = curve_fit(poly6, rsm.chi_arr[:, -1], rsm.tth_arr[:, -1])\n",
    "\n",
    "def generate_q_mask(qs,\n",
    "                    tth_ext,\n",
    "                    chi_ext,\n",
    "                    wavelength_ext,\n",
    "                    popts=[chi_upr_popt,\n",
    "                           chi_lwr_popt,\n",
    "                           tth_upr_popt,\n",
    "                           tth_lwr_popt],\n",
    "                    ext=0.05\n",
    "                    ):\n",
    "    \n",
    "    # Check extent parameters\n",
    "    for param in [tth_ext, chi_ext, wavelength_ext]:\n",
    "        if len(param) != 2:\n",
    "            raise ValueError('Input extents must be of length 2.')\n",
    "        if param[0] > param[1]:\n",
    "            raise ValueError('Input extents must be (minimum, maximum)')\n",
    "        \n",
    "    tth, chi, wavelength = q_2_polar(qs, degrees=True)\n",
    "\n",
    "    chi_upr_mask = chi <= poly6(tth, *popts[0]) * (1 + ext)\n",
    "    chi_lwr_mask = chi >= poly6(tth, *popts[1]) * (1 - ext)\n",
    "    tth_upr_mask = tth <= poly6(chi, *popts[2]) * (1 + ext)\n",
    "    tth_lwr_mask = tth >= poly6(chi, *popts[3]) * (1 - ext)\n",
    "\n",
    "    tth_mask = np.all([tth >= tth_ext[0] * (1 - ext),\n",
    "                       tth <= tth_ext[1] * (1 + ext)],\n",
    "                       axis=0)\n",
    "    chi_mask = np.all([chi >= chi_ext[0] * (1 - ext),\n",
    "                       chi <= chi_ext[1] * (1 + ext)],\n",
    "                       axis=0)\n",
    "\n",
    "    wavelength_mask = np.all([\n",
    "        wavelength >= wavelength_ext[0] * (1 - ext),\n",
    "        wavelength <= wavelength_ext[1] * (1 + ext)\n",
    "    ], axis=0)\n",
    "\n",
    "    q_mask = np.all([chi_lwr_mask,\n",
    "                     chi_upr_mask,\n",
    "                     tth_lwr_mask,\n",
    "                     tth_upr_mask,\n",
    "                     tth_mask,\n",
    "                     chi_mask,\n",
    "                     wavelength_mask], axis=0)\n",
    "    \n",
    "    return q_mask\n",
    "\n",
    "\n",
    "def fixed_pair_casting_indexing(pair_list,\n",
    "                                spot_qs,\n",
    "                                ref_qs,\n",
    "                                iter_max=50):\n",
    "\n",
    "    full_connections = []\n",
    "    full_orientations = []\n",
    "    full_connections_rmse = []\n",
    "    for i in tqdm(range(len(pair_list))):\n",
    "\n",
    "        pair = pair_list[i]\n",
    "        # pair_orientation = pair_orientations[keep_pair_mask][i]\n",
    "        pair_spot_inds = np.nonzero(~np.isnan(pair))[0]\n",
    "        pair_ref_inds = pair[pair_spot_inds]\n",
    "        prev_connection = pair.copy()\n",
    "\n",
    "        iter_count = 0\n",
    "        iter_max = 50\n",
    "        ITERATE = True\n",
    "        while ITERATE:\n",
    "            connection = pair.copy()\n",
    "            orientation, rmse = fit_orientation_index(prev_connection,\n",
    "                                                      spot_qs,\n",
    "                                                      ref_qs)\n",
    "\n",
    "            rot_qs = ref_qs @ orientation.as_matrix()\n",
    "            q_mask = generate_q_mask(rot_qs,\n",
    "                                     (min_tth, max_tth),\n",
    "                                     (min_chi, max_chi),\n",
    "                                     (min_wavelength, max_wavelength),\n",
    "                                     (q_mins, q_maxs),\n",
    "                                     degrees=True)\n",
    "\n",
    "            # kdtree built from spots so we can query the reference lattice and avoid non-crystallographic indexing\n",
    "            kdtree = KDTree(spot_qs)\n",
    "            pot_conn = kdtree.query_ball_point(rot_qs[q_mask], r=near_q)\n",
    "            # Remove original pair reflections\n",
    "            for ind in pair_ref_inds:\n",
    "                if ind in np.nonzero(q_mask)[0]:\n",
    "                    pot_conn[np.nonzero(np.nonzero(q_mask)[0] == ind)[0][0]] = []\n",
    "\n",
    "            # Expand connection\n",
    "            for conn_i, conn in enumerate(pot_conn):\n",
    "                if len(conn) > 0:\n",
    "                    # Remove reflections near original pair\n",
    "                    for ind in pair_spot_inds:\n",
    "                        if ind in conn:\n",
    "                            conn.remove(ind)\n",
    "                    if len(conn) == 0:\n",
    "                        continue\n",
    "                    elif len(conn) == 1:\n",
    "                        # Add candidate reflection\n",
    "                        connection[conn[0]] = np.nonzero(q_mask)[0][conn_i]\n",
    "                    else:\n",
    "                        # Add closest of multiple candidate reflections\n",
    "                        ref_dist, ref_idx = kdtree.query(rot_qs[q_mask][conn_i])\n",
    "                        connection[ref_idx] = np.nonzero(q_mask)[0][conn_i]\n",
    "            \n",
    "            # Compare connection with previous connection\n",
    "            connection_spots = np.nonzero(~np.isnan(connection))[0]\n",
    "            prev_connection_spots = np.nonzero(~np.isnan(prev_connection))[0]\n",
    "\n",
    "            if len(connection_spots) == len(prev_connection_spots):\n",
    "                connection_refs = connection[connection_spots]\n",
    "                prev_connection_refs = prev_connection[prev_connection_spots]\n",
    "\n",
    "                if (np.all(connection_spots == prev_connection_spots)\n",
    "                    and np.all(connection_refs == prev_connection_refs)):\n",
    "                    ITERATE = False\n",
    "\n",
    "            prev_connection = connection.copy()\n",
    "            iter_count += 1\n",
    "            if iter_count >= iter_max:\n",
    "                ITERATE = False\n",
    "                # Re-update orientation\n",
    "                orientation, rmse = fit_orientation_index(connection, \n",
    "                                                          spot_qs,\n",
    "                                                          ref_qs)\n",
    "                print(f'Max iterations reached for pair {i}.')\n",
    "\n",
    "        full_connections.append(connection)\n",
    "        full_orientations.append(orientation)\n",
    "        full_connections_rmse.append(rmse)\n",
    "        # if np.sum(~np.isnan(connection)) > 9:\n",
    "        #     break\n",
    "\n",
    "    return full_connections, full_orientations, full_connections_rmse\n",
    "\n",
    "\n",
    "def initial_pair_casting_indexing(pair_list,\n",
    "                                  spot_qs,\n",
    "                                  ref_qs,\n",
    "                                  iter_max=50):\n",
    "\n",
    "    full_connections = []\n",
    "    full_orientations = []\n",
    "    full_connections_rmse = []\n",
    "    for i in tqdm(range(len(pair_list))):\n",
    "\n",
    "        pair = pair_list[i]\n",
    "        prev_connection = pair.copy()\n",
    "\n",
    "        iter_count = 0\n",
    "        iter_max = 50\n",
    "        ITERATE = True\n",
    "        while ITERATE:\n",
    "            # Blank baseline connection\n",
    "            connection = pair.copy()\n",
    "            connection[:] = np.nan\n",
    "\n",
    "            orientation, rmse = fit_orientation_index(prev_connection,\n",
    "                                                      spot_qs,\n",
    "                                                      ref_qs)\n",
    "\n",
    "            rot_qs = ref_qs @ orientation.as_matrix()\n",
    "            q_mask = generate_q_mask(rot_qs,\n",
    "                                     (min_tth, max_tth),\n",
    "                                     (min_chi, max_chi),\n",
    "                                     (min_wavelength, max_wavelength),\n",
    "                                     ext=0.05)\n",
    "\n",
    "            # kdtree built from spots so we can query the reference lattice and avoid non-crystallographic indexing\n",
    "            kdtree = KDTree(spot_qs)\n",
    "            pot_conn = kdtree.query_ball_point(rot_qs[q_mask], r=near_q)\n",
    "\n",
    "            # Build new connection\n",
    "            for conn_i, conn in enumerate(pot_conn):\n",
    "                if len(conn) > 0:\n",
    "                    if len(conn) == 0:\n",
    "                        continue\n",
    "                    elif len(conn) == 1:\n",
    "                        # Add candidate reflection\n",
    "                        connection[conn[0]] = np.nonzero(q_mask)[0][conn_i]\n",
    "                    else:\n",
    "                        # Add closest of multiple candidate reflections\n",
    "                        ref_dist, ref_idx = kdtree.query(rot_qs[q_mask][conn_i])\n",
    "                        connection[ref_idx] = np.nonzero(q_mask)[0][conn_i]\n",
    "            \n",
    "            # Eliminate less than pairs and replace with pair\n",
    "            if np.sum(~np.isnan(connection)) <= 1:\n",
    "                connection = pair.copy()\n",
    "                ITERATE = False\n",
    "                orientation, rmse = fit_orientation_index(connection, \n",
    "                                                          spot_qs,\n",
    "                                                          ref_qs)\n",
    "                break\n",
    "\n",
    "            # Compare connection with previous connection\n",
    "            connection_spots = np.nonzero(~np.isnan(connection))[0]\n",
    "            prev_connection_spots = np.nonzero(~np.isnan(prev_connection))[0]\n",
    "\n",
    "            if len(connection_spots) == len(prev_connection_spots):\n",
    "                connection_refs = connection[connection_spots]\n",
    "                prev_connection_refs = prev_connection[prev_connection_spots]\n",
    "\n",
    "                if (np.all(connection_spots == prev_connection_spots)\n",
    "                    and np.all(connection_refs == prev_connection_refs)):\n",
    "                    ITERATE = False\n",
    "\n",
    "            prev_connection = connection.copy()\n",
    "            iter_count += 1\n",
    "            if iter_count >= iter_max:\n",
    "                ITERATE = False\n",
    "                # Re-update orientation\n",
    "                orientation, rmse = fit_orientation_index(connection, \n",
    "                                                          spot_qs,\n",
    "                                                          ref_qs)\n",
    "                # print(f'Max iterations reached for pair {i}.')\n",
    "\n",
    "        full_connections.append(connection)\n",
    "        full_orientations.append(orientation)\n",
    "        full_connections_rmse.append(rmse)\n",
    "\n",
    "    return full_connections, full_orientations, full_connections_rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quality_of_fit(spot_qs,\n",
    "                       ref_qs,\n",
    "                       all_ref_qs,\n",
    "                       all_ref_fs,\n",
    "                       sigma=near_q):\n",
    "    \n",
    "    # Requirements:\n",
    "    # 1. Penalize missing reflections weighted according to their expected intensity\n",
    "    # 2. Do not penalize extra reflections which are not indexed (allows for overlapping orientations)\n",
    "    # 3. Penalize reflections weighted by their distance from expected positions\n",
    "\n",
    "    # # Determine which reflections are indexed\n",
    "    # found_spot_mask = [tuple(ref) in [tuple(x) for x in ref_qs] for ref in all_ref_qs]\n",
    "\n",
    "    # Normalize structure_factors to approximate total expected intensity\n",
    "    # all_ref_fs /= np.sum(all_ref_fs)\n",
    "\n",
    "    dist = [np.sqrt(np.sum([(p - q)**2 for p, q in zip(v1, v2)]))\n",
    "                        for v1, v2 in zip(spot_qs, ref_qs)]\n",
    "\n",
    "    # # 1D Gaussian centered at zero\n",
    "    # def gauss_1d(x, amp, fwhm):\n",
    "    #     sigma = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
    "    #     return amp * np.exp(-(x)**2 / (2 * sigma**2))\n",
    "\n",
    "    # qof = np.sum(gauss_1d(np.asarray(dist),\n",
    "    #                       all_ref_fs[found_spot_mask],\n",
    "    #                       fwhm))\n",
    "    \n",
    "    # Gaussian with structure factor amplitude and near_q standard deviation\n",
    "    # centered at zero sampled at distance\n",
    "    # qof = np.sum(\n",
    "    #     np.log(all_ref_fs[found_spot_mask])\n",
    "    #     * np.exp(-(np.asarray(dist))**2\n",
    "    #              / (2 * sigma**2)))\n",
    "\n",
    "    # Gaussian with specified standard deviation\n",
    "    # centered at zero sampled at distance\n",
    "    qof = np.sum(np.exp(-(np.asarray(dist))**2 / (2 * sigma**2)))\n",
    "    # dist_qual /= len(spot_qs) # Normalized to one\n",
    "\n",
    "    # # int_explained = np.sum(all_ref_fs[found_spot_mask]) / np.sum(all_ref_fs)\n",
    "    # int_explained = len(spot_qs) / len(all_ref_fs)\n",
    "\n",
    "    # qof = 0.5 * (dist_qual + int_explained)\n",
    "    # norm_qof = qof\n",
    "        \n",
    "    # max_qof = np.log(np.sum(all_ref_fs))\n",
    "    max_qof = len(all_ref_qs)\n",
    "    norm_qof = qof / max_qof\n",
    "\n",
    "    return qof, norm_qof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding orientation 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17663 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 2582/17663 [00:09<00:53, 281.17it/s]C:\\Users\\emusterma\\AppData\\Local\\Temp\\ipykernel_16456\\3167248389.py:18: UserWarning: Optimal rotation is not uniquely or poorly defined for the given sets of vectors.\n",
      "  fit_orientation, fit_rssd = Rotation.align_vectors(fit_ref_qs, fit_spot_qs)\n",
      "100%|██████████| 17663/17663 [01:03<00:00, 277.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.5377.\n",
      "Finding orientation 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12056/12056 [00:38<00:00, 309.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.3411.\n",
      "Finding orientation 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10388/10388 [00:31<00:00, 325.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.3241.\n",
      "Finding orientation 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9255/9255 [00:28<00:00, 329.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.3045.\n",
      "Finding orientation 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7477/7477 [00:22<00:00, 331.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.2913.\n",
      "Finding orientation 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5473/5473 [00:16<00:00, 338.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.2868.\n",
      "Finding orientation 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3944/3944 [00:11<00:00, 338.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.2710.\n",
      "Finding orientation 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3297/3297 [00:10<00:00, 326.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.2539.\n",
      "Finding orientation 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2606/2606 [00:07<00:00, 346.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.2124.\n",
      "Finding orientation 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1814/1814 [00:04<00:00, 385.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.2036.\n",
      "Finding orientation 11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1340/1340 [00:03<00:00, 398.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.1926.\n",
      "Finding orientation 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 993/993 [00:02<00:00, 405.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.1805.\n",
      "Finding orientation 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 679/679 [00:01<00:00, 401.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.1763.\n",
      "Finding orientation 14.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:00<00:00, 414.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.1686.\n",
      "Finding orientation 15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:00<00:00, 421.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.1491.\n",
      "Finding orientation 16.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 315.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of fit is 0.1341.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Decompose orientation with pair casting\n",
    "best_connections = []\n",
    "excluded_spot_indices = []\n",
    "included_spot_mask = np.asarray([True,] * len(expanded_pair_list[0]))\n",
    "included_spot_mask[excluded_spot_indices] = False\n",
    "original_pair_list = expanded_pair_list[keep_pair_mask]\n",
    "pair_list = original_pair_list\n",
    "\n",
    "iter_count = 0\n",
    "ITERATE = True\n",
    "while ITERATE:\n",
    "    print(f'Finding orientation {iter_count + 1}.')\n",
    "\n",
    "    # Find new connections\n",
    "    connections, orientations, rmse = initial_pair_casting_indexing(pair_list,\n",
    "                                                                    spot_qs[included_spot_mask],\n",
    "                                                                    ref_qs)\n",
    "    \n",
    "    qof_norm_list = []\n",
    "    for conn, orientation in zip(connections, orientations):\n",
    "        rot_qs = orientation.apply(ref_qs, inverse=True)\n",
    "        q_mask = generate_q_mask(rot_qs,\n",
    "                                 (min_tth, max_tth),\n",
    "                                 (min_chi, max_chi),\n",
    "                                 (min_wavelength, max_wavelength),\n",
    "                                 ext=0.05)\n",
    "        \n",
    "        fit_spot_qs = spot_qs[included_spot_mask][np.nonzero(~np.isnan(conn))[0]]\n",
    "        fit_ref_qs = np.asarray(rot_qs)[conn[np.nonzero(~np.isnan(conn))[0]].astype(int)]\n",
    "        all_ref_qs = rot_qs[q_mask]\n",
    "        all_ref_fs = ref_fs[q_mask]\n",
    "\n",
    "        qof, norm_qof = get_quality_of_fit(fit_spot_qs, fit_ref_qs, all_ref_qs, all_ref_fs, sigma=near_q * 2)\n",
    "        qof_norm_list.append(norm_qof)\n",
    "\n",
    "    best_connection = connections[np.argmax(qof_norm_list)]\n",
    "    print(f'Quality of fit is {np.max(qof_norm_list):.4f}.')\n",
    "    \n",
    "    # Find best connection with highest connectivity\n",
    "    # connection_length = [np.sum(~np.isnan(conn)) for conn in connections]\n",
    "    # connection_mask = connection_length == np.max(connection_length)\n",
    "    # best_connection = connections[np.nonzero(connection_mask)[0][np.argmin(np.asarray(rmse)[connection_mask])]]\n",
    "    if np.sum(~np.isnan(best_connection)) <= 1: # I am not sure why this is even necessary\n",
    "        ITERATE = False\n",
    "        break\n",
    "    expanded_best_connection = np.asarray([np.nan,] * len(included_spot_mask))\n",
    "    expanded_best_connection[included_spot_mask] = best_connection\n",
    "    best_connections.append(expanded_best_connection)\n",
    "\n",
    "    # if iter_count == 0:\n",
    "    #     raise\n",
    "\n",
    "    # Update connections\n",
    "    excluded_spot_indices.extend(*list(np.nonzero(~np.isnan(expanded_best_connection))))\n",
    "    included_spot_mask[excluded_spot_indices] = False\n",
    "\n",
    "    # Remove pairs where spots have already been indexed\n",
    "    new_pairs = []\n",
    "    for pair in pair_list:\n",
    "        # All nan means the pair does not use any of the ecluded indices\n",
    "        if np.all([np.isnan(pair[index]) for index in np.nonzero(~np.isnan(best_connection))[0]]):\n",
    "            new_pairs.append(pair[np.isnan(best_connection)])\n",
    "    pair_list = np.asarray(new_pairs)\n",
    "\n",
    "    iter_count += 1\n",
    "    if (len(spot_qs) - len(excluded_spot_indices) < 1 # Impossible to solve orientation\n",
    "        or len(pair_list) < 1 # No more valid pairs to solve\n",
    "        or iter_count >= 50): # Avoid infinite loops\n",
    "        ITERATE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  4,  2,  6,  5,  4,  2,  4,  3,  3,  3,  2,  2,  2,  2,  3])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray([np.sum(~np.isnan(conn)) for conn in best_connections])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection':'3d'})\n",
    "\n",
    "colors = ['k',] * len(best_connections)\n",
    "# colors = ['black', 'blue', 'green', 'purple'] + ['none'] * (len(best_connections) - 4)\n",
    "\n",
    "for best_fit_ind in range(len(best_connections)):\n",
    "    if best_fit_ind > 0:\n",
    "        break\n",
    "\n",
    "    orientation, rmse = fit_orientation_index(best_connections[best_fit_ind],\n",
    "                                              spot_qs,\n",
    "                                              ref_qs)\n",
    "    # print(rmse)\n",
    "\n",
    "    #rot_qs = ref_qs @ orientation.as_matrix()\n",
    "    rot_qs = orientation.apply(ref_qs, inverse=True)\n",
    "    q_mask = generate_q_mask(rot_qs,\n",
    "                            (min_tth, max_tth),\n",
    "                            (min_chi, max_chi),\n",
    "                            (min_wavelength, max_wavelength),\n",
    "                            ext=0)\n",
    "\n",
    "    ax.scatter(*rot_qs[q_mask].T, s=ref_fs[q_mask] * 0.1, c=colors[best_fit_ind])\n",
    "\n",
    "    hkls = [ref_hkls[int(ind)] for ind in best_connections[best_fit_ind][~np.isnan(best_connections[best_fit_ind])]]\n",
    "    fit_spots = spot_qs[np.nonzero(~np.isnan(best_connections[best_fit_ind]))[0]]\n",
    "    for idx, hkl in enumerate(hkls):\n",
    "        ax.text(*fit_spots[idx], str(hkl), fontsize=8, c=colors[best_fit_ind])\n",
    "\n",
    "for edge in edges:\n",
    "    ax.plot(*edge.T, c='gray', lw=1)\n",
    "\n",
    "ax.scatter(*np.asarray(spot_qs).T, s = 1, c='r')\n",
    "ax.scatter(0, 0, 0, s=10, c='blue')\n",
    "ax.set_xlim(q_mins[0], q_maxs[0])\n",
    "ax.set_ylim(q_mins[1], q_maxs[1])\n",
    "ax.set_zlim(q_mins[2], q_maxs[2])\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170.  15. 180.]\n",
      "[170.  20. 180.]\n",
      "[ 170.   25. -180.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(best_connections)):\n",
    "    orientation, rmse = fit_orientation_index(best_connections[i], spot_qs, ref_qs)\n",
    "    print(orientation.as_euler('XZX', degrees=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 530/14023 [00:01<00:38, 349.51it/s]C:\\Users\\emusterma\\AppData\\Local\\Temp\\ipykernel_18408\\3167248389.py:18: UserWarning: Optimal rotation is not uniquely or poorly defined for the given sets of vectors.\n",
      "  fit_orientation, fit_rssd = Rotation.align_vectors(fit_ref_qs, fit_spot_qs)\n",
      "100%|██████████| 14023/14023 [00:39<00:00, 359.13it/s]\n"
     ]
    }
   ],
   "source": [
    "rmse_list = []\n",
    "qof_list = []\n",
    "norm_qof_list = []\n",
    "for conn in tqdm(connections):\n",
    "    orientation, rmse = fit_orientation_index(conn, spot_qs[included_spot_mask], ref_qs)\n",
    "\n",
    "    #rot_qs = ref_qs @ orientation.as_matrix()\n",
    "    rot_qs = orientation.apply(ref_qs, inverse=True)\n",
    "    q_mask = generate_q_mask(rot_qs,\n",
    "                            (min_tth, max_tth),\n",
    "                            (min_chi, max_chi),\n",
    "                            (min_wavelength, max_wavelength),\n",
    "                            ext=0.05)\n",
    "\n",
    "\n",
    "    fit_spot_qs = spot_qs[included_spot_mask][np.nonzero(~np.isnan(conn))[0]]\n",
    "    fit_ref_qs = np.asarray(rot_qs)[conn[np.nonzero(~np.isnan(conn))[0]].astype(int)]\n",
    "    all_ref_qs = rot_qs[q_mask]\n",
    "    all_ref_fs = ref_fs[q_mask]\n",
    "\n",
    "    qof, norm_qof = get_quality_of_fit(fit_spot_qs, fit_ref_qs, all_ref_qs, all_ref_fs, sigma=near_q * 1)\n",
    "\n",
    "    rmse_list.append(rmse)\n",
    "    qof_list.append(qof)\n",
    "    norm_qof_list.append(norm_qof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection':'3d'})\n",
    "\n",
    "plot_connection = connections[np.argmax(norm_qof_list)]\n",
    "# plot_connection = connections[np.nonzero(connection_mask)[0][np.argmin(np.asarray(rmse_list)[connection_mask])]]\n",
    "plot_connection = connections[11]\n",
    "plot_connection = np.asarray(connections)[connection_mask][1]\n",
    "\n",
    "orientation, rmse = fit_orientation_index(plot_connection,\n",
    "                                            spot_qs[included_spot_mask],\n",
    "                                            ref_qs)\n",
    "\n",
    "#rot_qs = ref_qs @ orientation.as_matrix()\n",
    "rot_qs = orientation.apply(ref_qs, inverse=True)\n",
    "q_mask = generate_q_mask(rot_qs,\n",
    "                        (min_tth, max_tth),\n",
    "                        (min_chi, max_chi),\n",
    "                        (min_wavelength, max_wavelength),\n",
    "                        ext=0.05)\n",
    "\n",
    "ax.scatter(*rot_qs[q_mask].T, s=ref_fs[q_mask] * 0.1, c='k')\n",
    "\n",
    "hkls = [ref_hkls[int(ind)] for ind in plot_connection[~np.isnan(plot_connection)]]\n",
    "fit_spots = spot_qs[included_spot_mask][np.nonzero(~np.isnan(plot_connection))[0]]\n",
    "for idx, hkl in enumerate(hkls):\n",
    "    ax.text(*fit_spots[idx], str(hkl), fontsize=8, c='k')\n",
    "\n",
    "for edge in edges:\n",
    "    ax.plot(*edge, c='gray', lw=1)\n",
    "\n",
    "ax.scatter(*np.asarray(spot_qs[included_spot_mask]).T, s = 1, c='r')\n",
    "ax.scatter(0, 0, 0, s=10, c='blue')\n",
    "ax.set_xlim(q_mins[0], q_maxs[0])\n",
    "ax.set_ylim(q_mins[1], q_maxs[1])\n",
    "ax.set_zlim(q_mins[2], q_maxs[2])\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrdmaptools.geometry.geometry import get_q_vect, q_2_polar, estimate_image_coords\n",
    "from xrdmaptools.utilities.math import wavelength_2_energy\n",
    "\n",
    "tth, chi, wavelength = q_2_polar(spot_qs[np.nonzero(~np.isnan(best_connections[0]))[0]], degrees=True)\n",
    "# coords = estimate_image_coords(np.asarray([tth, chi]).T, rsm.tth_arr, rsm.chi_arr)[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientation, rmse = fit_orientation_index(best_connections[0],\n",
    "                                          spot_qs,\n",
    "                                          ref_qs)\n",
    "\n",
    "#rot_qs = ref_qs @ orientation.as_matrix()\n",
    "rot_qs = orientation.apply(ref_qs, inverse=True)\n",
    "\n",
    "ref_tth, ref_chi, ref_wavelength = q_2_polar(np.asarray(rot_qs)[best_connections[0][np.nonzero(~np.isnan(best_connections[0]))[0]].astype(int)], degrees=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_plane_from_ai(ai, skip=50):\n",
    "    points = np.asarray([ai.position_array()[::skip, ::skip, i].ravel()\n",
    "                         for i in [2, 1, 0]])\n",
    "    \n",
    "    d = np.mean(points, axis=1, keepdims=True)\n",
    "    svd = np.linalg.svd(points - d)\n",
    "    d = d.squeeze()\n",
    "    # Plane normal n = (a, b, c) and point (d)\n",
    "    return svd[0][:, -1], d\n",
    "\n",
    "n, d = det_plane_from_ai(rsm.ai, skip=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class k_vector():\n",
    "    def __init__(self, point, tth, chi, degrees=False):\n",
    "        \n",
    "        self.x0, self.y0, self.z0 = point\n",
    "\n",
    "        if degrees:\n",
    "            tth = np.radians(tth)\n",
    "            chi = np.radians(chi)\n",
    "\n",
    "\n",
    "        self.a = np.sin(tth) * np.cos(chi)\n",
    "        self.b = np.sin(tth) * np.sin(chi)\n",
    "        self.c = np.cos(tth)\n",
    "            \n",
    "    def __call__(self, t):\n",
    "        return (self.x0 + self.a * t,\n",
    "                self.y0 + self.b * t,\n",
    "                self.z0 + self.c * t)\n",
    "    \n",
    "    def get_planar_intercept(self, a, b, c, d):\n",
    "\n",
    "        t = ((a * (d[0] - self.x0) + b * (d[1] - self.y0) + c * (d[2] - self.z0))\n",
    "             / (self.a * a + self.b * b + self.c * c))\n",
    "        \n",
    "        return self(t)\n",
    "    \n",
    "    def copy(self, point=None, tth=None, chi=None):\n",
    "        if point is None:\n",
    "            point = (self.x0, self.y0, self.z0)\n",
    "        if tth is None:\n",
    "            tth = self.tth\n",
    "        if chi is None:\n",
    "            chi = self.chi\n",
    "        \n",
    "        return self.__class__(point, tth, chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstsq_line_intersect(P0, P1):\n",
    "    # From Traa, Johannes \"Least-Squares Intersection of Lines\" (2013).\n",
    "    \n",
    "    # Generate all line direction vectors \n",
    "    n = (P1 - P0) / np.linalg.norm(P1 - P0, axis=1)[:, np.newaxis] # normalized\n",
    "\n",
    "    # Generate the array of all projectors \n",
    "    projs = np.eye(n.shape[1]) - n[:, :, np.newaxis] * n[:, np.newaxis]  # I - n*n.T\n",
    "\n",
    "    # Generate R matrix and q vector\n",
    "    R = projs.sum(axis=0)\n",
    "    q = (projs @ P0[:, :, np.newaxis]).sum(axis=0)\n",
    "\n",
    "    # Solve the least squares problem for the \n",
    "    # Intersection point p: Rp = q\n",
    "    p = np.linalg.lstsq(R, q, rcond=None)[0]\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004240267831336831\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection':'3d'})\n",
    "\n",
    "skip = 50\n",
    "\n",
    "pos_arr = rsm.ai.position_array()\n",
    "\n",
    "x = pos_arr[:, :, 2][::skip, ::skip].ravel()\n",
    "y = pos_arr[:, :, 1][::skip, ::skip].ravel()\n",
    "z = pos_arr[:, :, 0][::skip, ::skip].ravel()\n",
    "\n",
    "ax.scatter(x, y, z, s=1, c='k', alpha=0.1)\n",
    "ax.scatter(0, 0, 0, s=10, facecolors='none', edgecolors='r')\n",
    "# ax.scatter(xx.ravel(), yy.ravel(), zz.ravel(), s=1)\n",
    "\n",
    "spot_k_vectors = []\n",
    "ref_k_vectors = []\n",
    "P0 = []\n",
    "P1 = []\n",
    "for ind in range(len(tth)):\n",
    "\n",
    "        spot_k = k_vector((0, 0, 0), tth[ind], chi[ind], degrees=True)\n",
    "        spot_k_vectors.append(spot_k)\n",
    "        intercept = spot_k.get_planar_intercept(*n, d)\n",
    "\n",
    "\n",
    "        ref_k = k_vector(intercept, ref_tth[ind], ref_chi[ind], degrees=True)\n",
    "        ref_k_vectors.append(ref_k)\n",
    "\n",
    "        P0.append([ref_k.x0, ref_k.y0, ref_k.z0])\n",
    "        P1.append([ref_k.a, ref_k.b, ref_k.c])\n",
    "\n",
    "        ax.scatter(*intercept, s=1, c='r')\n",
    "\n",
    "        ax.plot(*spot_k(np.linspace(0, 0.5, 100)), c='r', lw=0.1)\n",
    "        ax.plot(*ref_k(np.linspace(-0.5, 0, 100)), c='blue', lw=0.1)\n",
    "\n",
    "        # Text\n",
    "        ax.text(*intercept,\n",
    "                str(tuple(np.asarray(ref_hkls)[best_connections[0][np.nonzero(~np.isnan(best_connections[0]))[0]].astype(int)][ind])),\n",
    "                fontsize=4, c='k')\n",
    "\n",
    "P0 = np.asarray(P0)\n",
    "P1 = np.asarray(P1)\n",
    "zero_point = lstsq_line_intersect(P0, P1).squeeze()\n",
    "print(np.linalg.norm(zero_point))\n",
    "ax.scatter(*zero_point, c='g', s=1)\n",
    "\n",
    "ax.set_xlabel('x [m]')\n",
    "ax.set_ylabel('y [m]')\n",
    "ax.set_zlabel('z [m]')\n",
    "ax.set_aspect('equal')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrdmaptools.geometry.geometry import q_2_polar, get_q_vect, vector_angle\n",
    "\n",
    "def apply_zero_point_correction(spot_qs,\n",
    "                                ref_qs,\n",
    "                                connection,\n",
    "                                ai):\n",
    "    # Combined find and correct zero point\n",
    "\n",
    "    if len(spot_qs) != len(ref_qs):\n",
    "        raise ValueError('Length of spots and assigned reference qs must be equal.')\n",
    "    \n",
    "    # Find detector plane\n",
    "    n, d = det_plane_from_ai(ai, skip=50)\n",
    "\n",
    "    # Convert to polar real-space coordinates\n",
    "    spot_tth, spot_chi, spot_wavelength = q_2_polar(spot_qs)\n",
    "    ref_tth, ref_chi, ref_wavelength = q_2_polar(ref_qs)\n",
    "\n",
    "    # Build vector points\n",
    "    intercepts = []\n",
    "    points0, points1 = [], []\n",
    "    for i in range(len(spot_qs)):\n",
    "        # Create vectors from original zero to intercept detector plane\n",
    "        spot_k = k_vector((0, 0, 0), spot_tth[i], spot_chi[i])\n",
    "        intercept = spot_k.get_planar_intercept(*n, d)\n",
    "        intercepts.append(intercept)\n",
    "        \n",
    "        # Draw reference vectors for detector intercepts back towards zero point\n",
    "        ref_k = k_vector(intercept, ref_tth[i], ref_chi[i])\n",
    "\n",
    "        # Convert reference vectors into two points\n",
    "        # Should be a direct way to do this\n",
    "        points0.append([ref_k.x0, ref_k.y0, ref_k.z0])\n",
    "        points1.append([ref_k.a, ref_k.b, ref_k.c])\n",
    "\n",
    "    zero_point = lstsq_line_intersect(np.asarray(points0),\n",
    "                                        np.asarray(points1)).squeeze()\n",
    "\n",
    "    dx, dy, dz = (np.asarray(intercepts) - zero_point).T\n",
    "    upd_tth = np.arccos(dz / np.sqrt(dx**2 + dy**2 + dz**2))\n",
    "    upd_chi = np.arctan(dy / dx)\n",
    "\n",
    "    corr_spot_qs = get_q_vect(upd_tth, upd_chi, spot_wavelength).T\n",
    "\n",
    "    return corr_spot_qs, tuple(zero_point)\n",
    "\n",
    "# Unused\n",
    "def get_zero_point(spot_qs,\n",
    "                   ref_qs,\n",
    "                   detector_plane_normal,\n",
    "                   detector_plane_point):\n",
    "    \n",
    "    if len(spot_qs) != len(ref_qs):\n",
    "        raise ValueError('Length of spots and assigned reference qs must be equal.')\n",
    "    \n",
    "    spot_tth, spot_chi, _ = q_2_polar(spot_qs)\n",
    "    ref_tth, ref_chi, _ = q_2_polar(ref_qs)\n",
    "\n",
    "    # Build vector points\n",
    "    points0, points1 = [], []\n",
    "    for i in range(len(spot_qs)):\n",
    "        \n",
    "        # Create vectors from original zero to intercept detector plane\n",
    "        spot_k = k_vector((0, 0, 0), spot_tth[i], spot_chi[i])\n",
    "        intercept = spot_k.get_planar_intercept(*detector_plane_normal,\n",
    "                                                detector_plane_point)\n",
    "        \n",
    "        # Draw reference vectors for detector intercepts back towards zero point\n",
    "        ref_k = k_vector(intercept, ref_tth[i], ref_chi[i])\n",
    "\n",
    "        # Convert reference vectors into two points\n",
    "        # Should be a direct way to do this\n",
    "        points0.append([ref_k.x0, ref_k.y0, ref_k.z0])\n",
    "        points1.append([ref_k.a, ref_k.b, ref_k.c])\n",
    "    \n",
    "    zero_point = lstsq_line_intersect(np.asarray(points0),\n",
    "                                      np.asarray(points1)).squeeze()\n",
    "    \n",
    "    return zero_point\n",
    "\n",
    "# Unused\n",
    "def correct_zero_point(spot_qs,\n",
    "                       zero_point,\n",
    "                       detector_plane_normal,\n",
    "                       detector_plane_point):\n",
    "    \n",
    "    tth, chi, wavelength = q_2_polar(spot_qs)\n",
    "\n",
    "    upd_tth, upd_chi = [], []\n",
    "    for i in range(len(spot_qs)):\n",
    "        # Draw original vector to determine planar intercetp\n",
    "        spot_k = k_vector((0, 0, 0), tth[i], chi[i])\n",
    "        intercept = spot_k.get_planar_intercept(*detector_plane_normal,\n",
    "                                                detector_plane_point)\n",
    "\n",
    "        # Intercept on detector plane minus the new zero_point\n",
    "        dx = intercept[0] - zero_point[0]\n",
    "        dy = intercept[1] - zero_point[1]\n",
    "        dz = intercept[2] - zero_point[2]\n",
    "\n",
    "        # Determine new polar angles from new zero point\n",
    "        upd_tth.append(vector_angle([dx, dy, dz], [0, 0, 1]))\n",
    "        upd_chi.append(np.arctan(dy / dx))\n",
    "\n",
    "    # Convert updated polar coordinates back to q-space\n",
    "    return get_q_vect(np.asarray(upd_tth), np.asarray(upd_chi), wavelength).T\n",
    "\n",
    "orientation, rmse = fit_orientation_index(best_connections[0],\n",
    "                                          spot_qs,\n",
    "                                          ref_qs)\n",
    "\n",
    "rot_qs = orientation.apply(ref_qs, inverse=True)\n",
    "\n",
    "corr_spot_qs, zero_point = apply_zero_point_correction(spot_qs[np.nonzero(~np.isnan(best_connections[0]))[0]],\n",
    "                                                       np.asarray(rot_qs)[best_connections[0][np.nonzero(~np.isnan(best_connections[0]))[0]].astype(int)],\n",
    "                                                       rsm.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection':'3d'})\n",
    "\n",
    "colors = ['k',] * len(best_connections)\n",
    "# colors = ['black', 'blue', 'green', 'purple'] + ['none'] * (len(best_connections) - 4)\n",
    "\n",
    "for best_fit_ind in range(len(best_connections)):\n",
    "    if best_fit_ind > 0:\n",
    "        break\n",
    "\n",
    "    orientation, rmse = fit_orientation_index(best_connections[best_fit_ind],\n",
    "                                              spot_qs,\n",
    "                                              ref_qs)\n",
    "\n",
    "    #rot_qs = ref_qs @ orientation.as_matrix()\n",
    "    rot_qs = orientation.apply(ref_qs, inverse=True)\n",
    "    q_mask = generate_q_mask(rot_qs,\n",
    "                            (min_tth, max_tth),\n",
    "                            (min_chi, max_chi),\n",
    "                            (min_wavelength, max_wavelength),\n",
    "                            ext=0.05)\n",
    "\n",
    "    ax.scatter(*rot_qs[q_mask].T, s=ref_fs[q_mask] * 0.1, c=colors[best_fit_ind])\n",
    "\n",
    "    hkls = [ref_hkls[int(ind)] for ind in best_connections[best_fit_ind][~np.isnan(best_connections[best_fit_ind])]]\n",
    "    fit_spots = spot_qs[np.nonzero(~np.isnan(best_connections[best_fit_ind]))[0]]\n",
    "    for idx, hkl in enumerate(hkls):\n",
    "        ax.text(*fit_spots[idx], str(hkl), fontsize=8, c=colors[best_fit_ind])\n",
    "\n",
    "for edge in edges:\n",
    "    ax.plot(*edge, c='gray', lw=1)\n",
    "\n",
    "ax.scatter(*np.asarray(spot_qs).T, s = 1, c='r', label='spots')\n",
    "ax.scatter(0, 0, 0, s=10, c='blue')\n",
    "\n",
    "ax.scatter(*np.asarray(corr_spot_qs).T, s=1, c='g')\n",
    "\n",
    "ax.set_xlim(q_mins[0], q_maxs[0])\n",
    "ax.set_ylim(q_mins[1], q_maxs[1])\n",
    "ax.set_zlim(q_mins[2], q_maxs[2])\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrdmaptools.crystal.crystal import LatticeParameters\n",
    "from scipy import linalg\n",
    "unstrained = LatticeParameters.from_Phase(stibnite)\n",
    "\n",
    "def get_strain_orientation(spot_qs, ref_hkls, unstrained):\n",
    "    I = np.eye(3)\n",
    "\n",
    "    spot_qs = np.asarray(spot_qs)\n",
    "    ref_hkls = np.asarray(ref_hkls)\n",
    "\n",
    "    if len(spot_qs) != len(ref_hkls):\n",
    "        raise ValueError('Number of spots and assigned hkl indices must be equal.')\n",
    "\n",
    "    # Fit deformation (displacement?) tensor\n",
    "    # x carries orientation and lattice parameter information\n",
    "    x, res, rnk, s = linalg.lstsq(ref_hkls,\n",
    "                                  spot_qs)\n",
    "\n",
    "    # Convert to Busing and Levy UB matrix. Remove 2pi factor\n",
    "    UBmat = x.T / (2 * np.pi)\n",
    "\n",
    "    # Polar decomposition to remove rotation components.\n",
    "    # The leftover U is the active rotation and the inverse (transpose) is required for passive definition. Maybe...\n",
    "    U, B = linalg.polar(UBmat, side='right')\n",
    "\n",
    "    # Build strained lattice parameters from the polar decomposed stretch tensor (B)\n",
    "    # B is defined in Busing and Levy and is comprised of the strained reciprocal lattice vectors\n",
    "    strained = LatticeParameters.from_UBmat(B)\n",
    "\n",
    "    # Get transformation tensor (T) between strained and unstrained lattices\n",
    "    Tij = np.dot(strained.Amat, np.linalg.inv(unstrained.Amat))\n",
    "    # Tij = np.dot(unstrained.Bmat, np.linalg.inv(B)) # Switched positions account for opposite sign\n",
    "\n",
    "    # Decompose transformation tensor into strain components\n",
    "    # Is this eulerian or langrangian strain? Or infinitesimal?\n",
    "    # This is still in crystal coordinates too...\n",
    "    eij_full = 0.5 * (Tij + Tij.T) - I\n",
    "    eij_hydro = np.trace(eij_full) / 3\n",
    "    eij_dev = eij_full - eij_hydro * I\n",
    "\n",
    "    return eij_dev, eij_hydro, Rotation.from_matrix(U.T)\n",
    "\n",
    "\n",
    "def apply_crystal_strain(ref_qs, eij_full):\n",
    "    return np.asarray(ref_qs) @ (np.eye - eij_full)\n",
    "\n",
    "def apply_sample_strain(ref_qs, eij_full):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def apply_crystal_strain_rotation(ref_qs, eij_full, orientaiton):\n",
    "    raise NotImplementedError()\n",
    "    return np.asarray(ref_qs) @ (np.eye - eij_full) @ orientation.T # maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.414665201165365\n",
      "[[  6.69874952  -4.99442553  10.44398435]\n",
      " [ -4.99442553  -1.95873001 -15.63233736]\n",
      " [ 10.44398435 -15.63233736  -4.74001952]]\n"
     ]
    }
   ],
   "source": [
    "eij_dev, eij_hydro, U = get_strain_orientation(\n",
    "    spot_qs[np.nonzero(~np.isnan(best_connections[0]))[0]],\n",
    "    np.asarray(ref_hkls)[best_connections[0][np.nonzero(~np.isnan(best_connections[0]))[0]].astype(int)],\n",
    "    unstrained)\n",
    "\n",
    "eij_full = eij_dev + eij_hydro * np.eye(3)\n",
    "\n",
    "print(eij_hydro * 1e3)\n",
    "print(eij_dev * 1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|a = 11.314000\t|b = 3.837000\t|c = 11.234000\n",
      "|alpha = 90.000\t|beta = 90.000 \t|gamma = 90.000\n"
     ]
    }
   ],
   "source": [
    "from xrdmaptools.crystal.crystal import LatticeParameters\n",
    "\n",
    "unstrained = LatticeParameters.from_Phase(stibnite)\n",
    "print(f'|a = {unstrained.a:.6f}\\t|b = {unstrained.b:.6f}\\t|c = {unstrained.c:.6f}')\n",
    "print(f'|alpha = {np.degrees(unstrained.alpha):.3f}\\t|beta = {np.degrees(unstrained.beta):.3f} \\t|gamma = {np.degrees(unstrained.gamma):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11.11341472  -4.99442553  10.44398435]\n",
      " [ -4.99442553   2.45593519 -15.63233736]\n",
      " [ 10.44398435 -15.63233736  -0.32535431]]\n",
      "4.414665201165365\n",
      "[[  6.69874952  -4.99442553  10.44398435]\n",
      " [ -4.99442553  -1.95873001 -15.63233736]\n",
      " [ 10.44398435 -15.63233736  -4.74001952]]\n",
      "|a = 11.439737\t|b = 3.846614\t|c = 11.238286\n",
      "|alpha = 91.803\t|beta = 88.804 \t|gamma = 90.571\n"
     ]
    }
   ],
   "source": [
    "from scipy import linalg\n",
    "from xrdmaptools.crystal.crystal import LatticeParameters\n",
    "I = np.eye(3)\n",
    "\n",
    "unstrained = LatticeParameters.from_Phase(stibnite)\n",
    "\n",
    "orientation, rmse = fit_orientation_index(best_connections[0],\n",
    "                                          spot_qs,\n",
    "                                          ref_qs)\n",
    "\n",
    "x, res, rnk, s = linalg.lstsq(np.asarray(ref_hkls)[best_connections[0][np.nonzero(~np.isnan(best_connections[0]))[0]].astype(int)],\n",
    "                              spot_qs[np.nonzero(~np.isnan(best_connections[0]))[0]])\n",
    "\n",
    "\n",
    "refs = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "spots = [[(2 * np.pi) / (11.314 * 1.01), 0, 0],\n",
    "         [0, (2 * np.pi) / (3.837 * 0.98), 0],\n",
    "         [0, 0, (2 * np.pi) / (11.234 * 1.03)]]\n",
    "\n",
    "spots = np.asarray(spots) @ Rotation.from_euler('xzx', [50, 10, 0]).as_matrix()\n",
    "\n",
    "# x, res, rnk, s = linalg.lstsq(refs, spots)\n",
    "\n",
    "UBmat = x.T / (2 * np.pi)\n",
    "U, B = linalg.polar(UBmat, side='right') # This U is transpose of orientation!!!\n",
    "strained = LatticeParameters.from_UBmat(B)\n",
    "\n",
    "Tij = np.dot(strained.Amat, np.linalg.inv(unstrained.Amat))\n",
    "# Tij = np.dot(unstrained.Bmat, np.linalg.inv(B)) # Also a valid option...\n",
    "eij_full = 0.5 * (Tij + Tij.T) - I\n",
    "eij_hydro = np.trace(eij_full) / 3\n",
    "eij_dev = eij_full - eij_hydro * I\n",
    "print(eij_full * 1e3)\n",
    "print(eij_hydro * 1e3)\n",
    "print(eij_dev * 1e3)\n",
    "# print(np.degrees(Rotation.from_matrix(orientation.as_matrix() @ U).magnitude()))\n",
    "print(f'|a = {strained.a:.6f}\\t|b = {strained.b:.6f}\\t|c = {strained.c:.6f}')\n",
    "print(f'|alpha = {np.degrees(strained.alpha):.3f}\\t|beta = {np.degrees(strained.beta):.3f} \\t|gamma = {np.degrees(strained.gamma):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11.05635246  -4.88435407  10.49041302]\n",
      " [ -4.88435407   2.20503638 -15.72437996]\n",
      " [ 10.49041302 -15.72437996   0.29407983]]\n",
      "4.518489556528597\n",
      "[[  6.5378629   -4.88435407  10.49041302]\n",
      " [ -4.88435407  -2.31345318 -15.72437996]\n",
      " [ 10.49041302 -15.72437996  -4.22440973]]\n"
     ]
    }
   ],
   "source": [
    "Tij = np.dot(unstrained.Bmat, np.linalg.inv(B))\n",
    "# Tij = np.dot(unstrained.Bmat, np.linalg.inv(UBmat))\n",
    "# Tij = np.dot(UBmat, np.linalg.inv(unstrained.Bmat))\n",
    "# Tij = np.dot(np.linalg.inv(UBmat), unstrained.Bmat)\n",
    "# Tij = np.dot(np.linalg.inv(unstrained.Bmat), UBmat)\n",
    "eij_full = 0.5 * (Tij + Tij.T) - I\n",
    "eij_hydro = np.trace(eij_full) / 3\n",
    "eij_dev = eij_full - eij_hydro * I\n",
    "print(eij_full * 1e3)\n",
    "print(eij_hydro * 1e3)\n",
    "print(eij_dev * 1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.08139997e-16, -4.74514000e-15,  4.51479340e-15])"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wij = 0.5 * (Tij - Tij.T)\n",
    "w = [wij[2, 1], wij[0, 2], wij[1, 0]]\n",
    "np.degrees(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emusterma\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3466: UserWarning: Gimbal lock detected. Setting third angle to zero since it is not possible to uniquely determine all angles.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.08139997e-16, 6.54978725e-15, 0.00000000e+00])"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rotation.from_matrix(wij + I).as_euler('xzx', degrees=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19.59543486 12.2086758  19.6670827 ]\n",
      " [12.2086758  -2.60335478 25.57793052]\n",
      " [19.6670827  25.57793052  0.1073777 ]]\n",
      "5.699819262548737\n",
      "[[13.8956156  12.2086758  19.6670827 ]\n",
      " [12.2086758  -8.30317404 25.57793052]\n",
      " [19.6670827  25.57793052 -5.59244156]]\n",
      "1.2494266459753685\n",
      "|a = 11.535703\t|b = 3.828158\t|c = 11.258569\n",
      "|alpha = 87.020\t|beta = 87.751 \t|gamma = 88.598\n"
     ]
    }
   ],
   "source": [
    "from scipy import linalg\n",
    "from xrdmaptools.crystal.crystal import LatticeParameters\n",
    "I = np.eye(3)\n",
    "\n",
    "unstrained = LatticeParameters.from_Phase(stibnite)\n",
    "\n",
    "orientation, rmse = fit_orientation_index(best_connections[0],\n",
    "                                          spot_qs,\n",
    "                                          ref_qs)\n",
    "\n",
    "# x, res, rnk, s = linalg.lstsq(np.asarray(ref_hkls)[best_connections[0][np.nonzero(~np.isnan(best_connections[0]))[0]].astype(int)],\n",
    "#                               corr_spot_qs)\n",
    "\n",
    "UBmat = x.T / (2 * np.pi)\n",
    "U, B = linalg.polar(UBmat, side='right') # This U is transpose of orientation!!!\n",
    "strained = LatticeParameters.from_UBmat(B)\n",
    "\n",
    "Tij = np.dot(strained.Amat, np.linalg.inv(unstrained.Amat))\n",
    "eij_full = 0.5 * (Tij + Tij.T) - I\n",
    "eij_hydro = np.trace(eij_full) / 3\n",
    "eij_dev = eij_full - eij_hydro * I\n",
    "print(eij_full * 1e3)\n",
    "print(eij_hydro * 1e3)\n",
    "print(eij_dev * 1e3)\n",
    "print(np.degrees(Rotation.from_matrix(orientation.as_matrix() @ U).magnitude()))\n",
    "print(f'|a = {strained.a:.6f}\\t|b = {strained.b:.6f}\\t|c = {strained.c:.6f}')\n",
    "print(f'|alpha = {np.degrees(strained.alpha):.3f}\\t|beta = {np.degrees(strained.beta):.3f} \\t|gamma = {np.degrees(strained.gamma):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection':'3d'})\n",
    "\n",
    "colors = ['k',] * len(best_connections)\n",
    "# colors = ['black', 'blue', 'green', 'purple'] + ['none'] * (len(best_connections) - 4)\n",
    "\n",
    "for best_fit_ind in range(len(best_connections)):\n",
    "    if best_fit_ind > 0:\n",
    "        break\n",
    "\n",
    "    orientation, rmse = fit_orientation_index(best_connections[best_fit_ind],\n",
    "                                              spot_qs,\n",
    "                                              ref_qs)\n",
    "\n",
    "    rot_qs = Rotation.from_matrix(U.as_matrix()).apply(ref_qs, inverse=True)\n",
    "\n",
    "    q_mask = generate_q_mask(rot_qs,\n",
    "                            (min_tth, max_tth),\n",
    "                            (min_chi, max_chi),\n",
    "                            (min_wavelength, max_wavelength),\n",
    "                            ext=0.05)\n",
    "\n",
    "    ax.scatter(*rot_qs[q_mask].T, s=ref_fs[q_mask] * 0.1, c=colors[best_fit_ind])\n",
    "\n",
    "    hkls = [ref_hkls[int(ind)] for ind in best_connections[best_fit_ind][~np.isnan(best_connections[best_fit_ind])]]\n",
    "    fit_spots = spot_qs[~np.isnan(best_connections[best_fit_ind])]\n",
    "    for idx, hkl in enumerate(hkls):\n",
    "        ax.text(*fit_spots[idx], str(hkl), fontsize=8, c=colors[best_fit_ind])\n",
    "\n",
    "for edge in edges:\n",
    "    ax.plot(*edge.T, c='gray', lw=1)\n",
    "\n",
    "ax.scatter(*np.asarray(spot_qs).T, s = 1, c='r')\n",
    "ax.scatter(0, 0, 0, s=10, c='blue')\n",
    "\n",
    "fit_qs = ref_qs @ (np.eye(3) - eij_full) @ U.as_matrix()\n",
    "\n",
    "ax.scatter(*fit_qs[q_mask].T, s=ref_fs[q_mask] * 0.1, c='g')\n",
    "\n",
    "ax.set_xlim(q_mins[0], q_maxs[0])\n",
    "ax.set_ylim(q_mins[1], q_maxs[1])\n",
    "ax.set_zlim(q_mins[2], q_maxs[2])\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00843589,  0.02070806,  0.00337127])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot_vector = np.median(spot_qs[~np.isnan(best_connections[0])]\n",
    "                     - rot_qs[best_connections[0][~np.isnan(best_connections[0])].astype(int)], axis=0)\n",
    "rot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00213625,  0.01145039, -0.00206447])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strain_vector = np.median(spot_qs[~np.isnan(best_connections[0])]\n",
    "                        - fit_qs[best_connections[0][~np.isnan(best_connections[0])].astype(int)], axis=0)\n",
    "strain_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0025169342740779766"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum([x**2 for x in strain_vector]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection': '3d'})\n",
    "\n",
    "vectors = spot_qs[~np.isnan(best_connections[0])] - rot_qs[best_connections[0][~np.isnan(best_connections[0])].astype(int)]\n",
    "ax.quiver(*spot_qs[~np.isnan(best_connections[0])].T, *vectors.T, lw=1, color='r')\n",
    "\n",
    "vectors = spot_qs[~np.isnan(best_connections[0])] - fit_qs[best_connections[0][~np.isnan(best_connections[0])].astype(int)]\n",
    "ax.quiver(*spot_qs[~np.isnan(best_connections[0])].T, *vectors.T, lw=1, color='g')\n",
    "\n",
    "# for i in range(len(vectors)):\n",
    "#     ax.arrow(*spot_qs[~np.isnan(best_connections[0])][i], *vectors[i])\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection': '3d'})\n",
    "\n",
    "vectors = spot_qs[~np.isnan(best_connections[0])] - rot_qs[best_connections[0][~np.isnan(best_connections[0])].astype(int)]\n",
    "ax.quiver(*np.zeros((3, len(spot_qs[~np.isnan(best_connections[0])]))), *vectors.T, lw=1, color='r')\n",
    "\n",
    "vectors = spot_qs[~np.isnan(best_connections[0])] - fit_qs[best_connections[0][~np.isnan(best_connections[0])].astype(int)]\n",
    "ax.quiver(*np.zeros((3, len(spot_qs[~np.isnan(best_connections[0])]))), *vectors.T, lw=1, color='g')\n",
    "\n",
    "# for i in range(len(vectors)):\n",
    "#     ax.arrow(*spot_qs[~np.isnan(best_connections[0])][i], *vectors[i])\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'scipy.spatial.transform._rotation.Rotation' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 16\u001b[0m\n\u001b[0;32m     10\u001b[0m orientation, rmse \u001b[38;5;241m=\u001b[39m fit_orientation_index(best_connections[best_fit_ind],\n\u001b[0;32m     11\u001b[0m                                           spot_qs,\n\u001b[0;32m     12\u001b[0m                                           ref_qs)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# rot_qs = ref_qs @ orientation.as_matrix()\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# rot_qs = orientation.apply(ref_qs, inverse=True)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m rot_qs \u001b[38;5;241m=\u001b[39m Rotation\u001b[38;5;241m.\u001b[39mfrom_matrix(\u001b[43mU\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m)\u001b[38;5;241m.\u001b[39mapply(ref_qs, inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m q_mask \u001b[38;5;241m=\u001b[39m generate_q_mask(rot_qs,\n\u001b[0;32m     19\u001b[0m                         (min_tth, max_tth),\n\u001b[0;32m     20\u001b[0m                         (min_chi, max_chi),\n\u001b[0;32m     21\u001b[0m                         (min_wavelength, max_wavelength),\n\u001b[0;32m     22\u001b[0m                         ext\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     24\u001b[0m ax\u001b[38;5;241m.\u001b[39mscatter(\u001b[38;5;241m*\u001b[39mrot_qs[q_mask]\u001b[38;5;241m.\u001b[39mT, s\u001b[38;5;241m=\u001b[39mref_fs[q_mask] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m, c\u001b[38;5;241m=\u001b[39mcolors[best_fit_ind], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munstrained ref\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'scipy.spatial.transform._rotation.Rotation' object has no attribute 'T'"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection':'3d'})\n",
    "\n",
    "colors = ['k',] * len(best_connections)\n",
    "# colors = ['black', 'blue', 'green', 'purple'] + ['none'] * (len(best_connections) - 4)\n",
    "\n",
    "for best_fit_ind in range(len(best_connections)):\n",
    "    if best_fit_ind > 0:\n",
    "        break\n",
    "\n",
    "    orientation, rmse = fit_orientation_index(best_connections[best_fit_ind],\n",
    "                                              spot_qs,\n",
    "                                              ref_qs)\n",
    "\n",
    "    # rot_qs = ref_qs @ orientation.as_matrix()\n",
    "    # rot_qs = orientation.apply(ref_qs, inverse=True)\n",
    "    rot_qs = Rotation.from_matrix(U.T).apply(ref_qs, inverse=True)\n",
    "\n",
    "    q_mask = generate_q_mask(rot_qs,\n",
    "                            (min_tth, max_tth),\n",
    "                            (min_chi, max_chi),\n",
    "                            (min_wavelength, max_wavelength),\n",
    "                            ext=0)\n",
    "\n",
    "    ax.scatter(*rot_qs[q_mask].T, s=ref_fs[q_mask] * 0.1, c=colors[best_fit_ind], label='unstrained ref')\n",
    "\n",
    "    hkls = [ref_hkls[int(ind)] for ind in best_connections[best_fit_ind][~np.isnan(best_connections[best_fit_ind])]]\n",
    "    # fit_spots = spot_qs[np.nonzero(~np.isnan(best_connections[best_fit_ind]))[0]]\n",
    "    fit_spots = corr_spot_qs\n",
    "    for idx, hkl in enumerate(hkls):\n",
    "        ax.text(*fit_spots[idx], str(hkl), fontsize=8, c=colors[best_fit_ind])\n",
    "\n",
    "for edge in edges:\n",
    "    ax.plot(*edge.T, c='gray', lw=1)\n",
    "\n",
    "ax.scatter(*np.asarray(corr_spot_qs).T, s = 1, c='r', label='offset spots')\n",
    "ax.scatter(0, 0, 0, s=10, c='blue', label='(000)')\n",
    "\n",
    "fit_qs = ref_qs @ (I - eij_full) @ U.T\n",
    "\n",
    "ax.scatter(*fit_qs[q_mask].T, s=ref_fs[q_mask] * 0.1, c='g', label='strained ref')\n",
    "\n",
    "ax.set_xlim(q_mins[0], q_maxs[0])\n",
    "ax.set_ylim(q_mins[1], q_maxs[1])\n",
    "ax.set_zlim(q_mins[2], q_maxs[2])\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "ax.legend()\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.238 -1.655 -2.317]\n",
      " [-1.655  6.24  -3.025]\n",
      " [-2.317 -3.025  9.454]]\n",
      "4.819\n",
      "[[-6.057 -1.655 -2.317]\n",
      " [-1.655  1.421 -3.025]\n",
      " [-2.317 -3.025  4.635]]\n",
      "[-47.745  11.565  51.037]\n"
     ]
    }
   ],
   "source": [
    "from scipy import linalg\n",
    "I = np.eye(3)\n",
    "\n",
    "orientation, rmse = fit_orientation_index(best_connections[0],\n",
    "                                          spot_qs,\n",
    "                                          ref_qs)\n",
    "\n",
    "rot_spot_qs = orientation.apply(spot_qs[np.nonzero(~np.isnan(best_connections[0]))[0]], inverse=False)\n",
    "\n",
    "x, res, rnk, s = linalg.lstsq(np.asarray(ref_hkls)[best_connections[0][np.nonzero(~np.isnan(best_connections[0]))[0]].astype(int)],\n",
    "                              spot_qs[np.nonzero(~np.isnan(best_connections[0]))[0]])\n",
    "\n",
    "UBmat = x.T / (2 * np.pi)\n",
    "U, B = linalg.polar(UBmat, side='left')\n",
    "strained = LatticeParameters.from_UBmat(B)\n",
    "\n",
    "U, B = linalg.polar(UBmat, side='right')\n",
    "strained = LatticeParameters.from_UBmat(B)\n",
    "\n",
    "Tij = np.dot(strained.Amat, np.linalg.inv(unstrained.Amat))\n",
    "eij_full = 0.5 * (Tij + Tij.T) - I\n",
    "eij_hydro = np.trace(eij_full) / 3\n",
    "eij_dev = eij_full - eij_hydro * I\n",
    "\n",
    "print(eij_full.round(6) * 1e3)\n",
    "print(eij_hydro.round(6) * 1e3)\n",
    "print(eij_dev.round(6) * 1e3)\n",
    "\n",
    "print(np.degrees(Rotation.from_matrix(U).as_euler('xzx')).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5547912673484892, 0, 0],\n",
       " [0, 1.6342569765810016, 0],\n",
       " [0, 0, 0.5576279268993436]]"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spots = [[(2 * np.pi) / (11.314 * 1.001), 0, 0],\n",
    "         [0, (2 * np.pi) / (3.837 * 1.002), 0],\n",
    "         [0, 0, (2 * np.pi) / (11.234 * 1.003)]]\n",
    "spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.554791, 0.      , 0.      ],\n",
       "       [0.      , 1.63425 , 0.      ],\n",
       "       [0.      , 0.      , 0.557623]])"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "([[(2 * np.pi) / (11.314), 0, 0],\n",
    "[0, (2 * np.pi) / (3.837), 0],\n",
    "[0, 0, (2 * np.pi) / (11.234)]] @ (I - eij_full)).round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 11.314\n",
      "b = 3.837\n",
      "c = 11.234\n",
      "alpha = 90.0\n",
      "beta = 90.0\n",
      "gamma = 90.0\n",
      "a = 11.29999799841607\n",
      "b = 3.8609654896003085\n",
      "c = 11.340530969453713\n",
      "alpha = 90.34248192109521\n",
      "beta = 90.26303930871917\n",
      "gamma = 90.18852746913046\n"
     ]
    }
   ],
   "source": [
    "for lattice in [unstrained, strained]:\n",
    "    print(f'a = {lattice.a}')\n",
    "    print(f'b = {lattice.b}')\n",
    "    print(f'c = {lattice.c}')\n",
    "    print(f'alpha = {np.degrees(lattice.alpha)}')\n",
    "    print(f'beta = {np.degrees(lattice.beta)}')\n",
    "    print(f'gamma = {np.degrees(lattice.gamma)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding valid higher order connections...\n",
      "Pair 17/125481   |3s: 1303   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[370], line 76\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m R1 \u001b[38;5;129;01min\u001b[39;00m pair_orientations[keep_pair_mask][rem_pair_mask]:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(R0, \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(R1, \u001b[38;5;28mfloat\u001b[39m):\n\u001b[1;32m---> 76\u001b[0m         misorientations\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mdegrees(Rotation\u001b[38;5;241m.\u001b[39mfrom_matrix(R0\u001b[38;5;241m.\u001b[39mas_matrix() \u001b[38;5;241m@\u001b[39m R1\u001b[38;5;241m.\u001b[39mas_matrix()\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mmagnitude()))\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m         misorientations\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# Cannot neglect colinear pairs\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Brute-force exhaustive search to find all higher order connection from list of valid pairs\n",
    "\n",
    "valid_conn = dict(zip(\n",
    "    range(2, 21),\n",
    "    [[] for _ in range(20)]\n",
    "))\n",
    "\n",
    "# Already know all valid pairs\n",
    "valid_conn[2] = np.asarray(expanded_pair_list[keep_pair_mask])\n",
    "\n",
    "def print_output(pair_iteration):\n",
    "    out_str = f\"Pair {pair_iteration + 1}/{len(valid_conn[2])}   \"\n",
    "\n",
    "    for rank in range(3, len(valid_conn.keys()) + 2):\n",
    "        rank_len = len(valid_conn[rank])\n",
    "        if rank_len > 0:\n",
    "            out_str += f\"|{rank}s: {rank_len}   \"\n",
    "\n",
    "    print(out_str, end='\\r')\n",
    "\n",
    "\n",
    "def scrub_repeats(connections_to_check,\n",
    "                   connections_to_scrub):\n",
    "    \n",
    "    connections_to_keep = []\n",
    "    \n",
    "    if len(connections_to_check) > 0:\n",
    "        connections_to_check = np.asarray(connections_to_check)\n",
    "    else:\n",
    "        return connections_to_scrub # Assumes no repeats in input set...\n",
    "\n",
    "    for connection in connections_to_scrub:\n",
    "        indices = np.nonzero(~np.isnan(connection))[0]\n",
    "        vals = connection[indices]\n",
    "\n",
    "        if np.any(np.all([connections_to_check[:, index] == val\n",
    "                       for index, val in zip(indices, vals)], axis=0)):\n",
    "            continue\n",
    "        else:\n",
    "            connections_to_keep.append(connection)\n",
    "        \n",
    "    return connections_to_keep\n",
    "\n",
    "\n",
    "print('Finding valid higher order connections...')\n",
    "rem_pair_mask = np.asarray([True,] * len(valid_conn[2]))\n",
    "for i in range(len(valid_conn[2])):\n",
    "\n",
    "    # def trunc(values, decs=0):\n",
    "    #     return np.trunc(values * 10**decs) / (10**decs)\n",
    "\n",
    "    # # similar_pair_mask = trunc(pair_rmse, 13) == trunc(pair_rmse[2], 13)\n",
    "    # similar_pair_mask = np.round(pair_rmse, 10) == np.round(pair_rmse[i], 10)\n",
    "    # sym_pairs = expanded_pair_list[similar_pair_mask]\n",
    "    # if len(sym_pairs) > 2:\n",
    "    #     most_positive_index = np.argmax([np.sign(np.asarray(ref_hkls)[pair[np.nonzero(~np.isnan(pair))[0]].astype(int)]).sum()\n",
    "    #                                     for pair in sym_pairs])\n",
    "    #     # most_positive_index = np.sign(np.asarray(ref_hkls)[sym_pairs[np.nonzero(~np.isnan(sym_pairs))].astype(int)].reshape(-1, 2, 3)).sum(axis=(1, 2)).argmax()\n",
    "\n",
    "    #     if i != np.nonzero(similar_pair_mask)[0][most_positive_index]:\n",
    "    #         continue\n",
    "\n",
    "    print_output(i)\n",
    "    pair = valid_conn[2][i]\n",
    "    pair_indices = np.nonzero(~np.isnan(pair))[0]\n",
    "    pair_vals = pair[pair_indices]\n",
    "\n",
    "    # rem_pair_mask = np.asarray([True,] * len(expanded_pair_list))\n",
    "    # rem_pair_mask[: i + 1] = False\n",
    "\n",
    "    # Eliminate remaining pair misorientations above some threshold\n",
    "    R0 = pair_orientations[keep_pair_mask][i]\n",
    "    misorientations = []\n",
    "    for R1 in pair_orientations[keep_pair_mask][rem_pair_mask]:\n",
    "        if not isinstance(R0, float) and not isinstance(R1, float):\n",
    "            misorientations.append(np.degrees(Rotation.from_matrix(R0.as_matrix() @ R1.as_matrix().T).magnitude()))\n",
    "        else:\n",
    "            misorientations.append(0) # Cannot neglect colinear pairs\n",
    "\n",
    "    misorientation_mask = rem_pair_mask.copy() # redundant, but differentiates\n",
    "    misorientation_mask[np.nonzero(rem_pair_mask)] = np.asarray(misorientations) < 360\n",
    "\n",
    "    # Initial triplet candidates\n",
    "    trip_mask = np.any([valid_conn[2][:, pair_indices[i]] == pair_vals[i] for i in range(2)], axis=0)\n",
    "    trip_mask = trip_mask & misorientation_mask\n",
    "    if np.sum(trip_mask) < 1:\n",
    "        continue\n",
    "    \n",
    "    next_pair0_mask = valid_conn[2][trip_mask, pair_indices[0]] == pair_vals[0]\n",
    "    next_pairs0 = valid_conn[2][trip_mask][next_pair0_mask]\n",
    "    next_pairs0[:, pair_indices[0]] = np.nan\n",
    "\n",
    "    next_pair1_mask = valid_conn[2][trip_mask, pair_indices[1]] == pair_vals[1]\n",
    "    next_pairs1 = valid_conn[2][trip_mask][next_pair1_mask]\n",
    "    next_pairs1[:, pair_indices[1]] = np.nan\n",
    "\n",
    "    partials3 = np.asarray([match for match in next_pairs0 if match in next_pairs1])\n",
    "    full3 = []\n",
    "    for triplet in partials3:\n",
    "        new_triplet = pair.copy()\n",
    "        new_triplet[~np.isnan(triplet)] = triplet[~np.isnan(triplet)].ravel()\n",
    "        valid_conn[3].append(new_triplet)\n",
    "        full3.append(new_triplet)\n",
    "\n",
    "    # Must have at least 2 triplets to search for qudruplets\n",
    "    if len(partials3) < 2:\n",
    "        continue\n",
    "\n",
    "    continue\n",
    "\n",
    "    for idx4 in range(len(partials3)):\n",
    "        print_output(i)\n",
    "        partials4, full4 = _find_next_connections(valid_conn[2][misorientation_mask],\n",
    "                                                  partials3,\n",
    "                                                  full3[idx4],\n",
    "                                                  common_partial=partials3[idx4])\n",
    "        \n",
    "        valid_conn[4].extend(scrub_repeats(valid_conn[4], full4))\n",
    "        \n",
    "        if len(partials4) < 2:\n",
    "            continue\n",
    "\n",
    "        for idx5 in range(len(partials4)):\n",
    "            print_output(i)\n",
    "            partials5, full5 = _find_next_connections(valid_conn[2][misorientation_mask],\n",
    "                                                      partials4,\n",
    "                                                      full4[idx5],\n",
    "                                                      common_partial=partials4[idx5])\n",
    "            \n",
    "            valid_conn[5].extend(scrub_repeats(valid_conn[5], full5))\n",
    "            \n",
    "            if len(partials5) < 2:\n",
    "                continue\n",
    "\n",
    "            for idx6 in range(len(partials5)):\n",
    "                print_output(i)\n",
    "                partials6, full6 = _find_next_connections(valid_conn[2][misorientation_mask],\n",
    "                                                          partials5,\n",
    "                                                          full5[idx6],\n",
    "                                                          common_partial=partials5[idx6])\n",
    "                \n",
    "                valid_conn[6].extend(scrub_repeats(valid_conn[6], full6))\n",
    "                \n",
    "                if len(partials6) < 2:\n",
    "                    continue\n",
    "                    \n",
    "                for idx7 in range(len(partials6)):\n",
    "                    print_output(i)\n",
    "                    partials7, full7 = _find_next_connections(valid_conn[2][misorientation_mask],\n",
    "                                                              partials6,\n",
    "                                                              full6[idx7],\n",
    "                                                              common_partial=partials6[idx7])\n",
    "                    \n",
    "                    valid_conn[7].extend(scrub_repeats(valid_conn[7], full7))\n",
    "                    \n",
    "                    if len(partials7) < 2:\n",
    "                        continue\n",
    "\n",
    "                    for idx8 in range(len(partials7)):\n",
    "                        print_output(i)\n",
    "                        partials8, full8 = _find_next_connections(valid_conn[2][misorientation_mask],\n",
    "                                                                  partials7,\n",
    "                                                                  full7[idx8],\n",
    "                                                                  common_partial=partials7[idx8])\n",
    "                        \n",
    "                        valid_conn[8].extend(scrub_repeats(valid_conn[8], full8))\n",
    "                        \n",
    "                        if len(partials8) < 2:\n",
    "                            continue\n",
    "\n",
    "                        for idx9 in range(len(partials8)):\n",
    "                            print_output(i)\n",
    "                            partials9, full9 = _find_next_connections(valid_conn[2][misorientation_mask],\n",
    "                                                                      partials8,\n",
    "                                                                      full8[idx9],\n",
    "                                                                      common_partial=partials8[idx9])\n",
    "                            \n",
    "                            valid_conn[9].extend(scrub_repeats(valid_conn[9], full9))\n",
    "                            \n",
    "                            if len(partials9) < 2:\n",
    "                                continue\n",
    "                        \n",
    "                            for idx10 in range(len(partials9)):\n",
    "                                print_output(i)\n",
    "                                partials10, full10 = _find_next_connections(valid_conn[2][misorientation_mask],\n",
    "                                                                            partials9,\n",
    "                                                                            full9[idx10],\n",
    "                                                                            common_partial=partials9[idx10])\n",
    "                                \n",
    "                                valid_conn[10].extend(scrub_repeats(valid_conn[10], full10))\n",
    "                                \n",
    "                                if len(partials10) < 2:\n",
    "                                    continue\n",
    "\n",
    "                                for idx11 in range(len(partials10)):\n",
    "                                    print_output(i)\n",
    "                                    partials11, full11 = _find_next_connections(valid_conn[2][misorientation_mask],\n",
    "                                                                                partials10,\n",
    "                                                                                full10[idx11],\n",
    "                                                                                common_partial=partials10[idx11])\n",
    "                                    \n",
    "                                    valid_conn[11].extend(scrub_repeats(valid_conn[11], full11))\n",
    "                                    \n",
    "                                    if len(partials11) < 2:\n",
    "                                        continue\n",
    "\n",
    "                                    for idx12 in range(len(partials11)):\n",
    "                                        print_output(i)\n",
    "                                        partials12, full12 = _find_next_connections(valid_conn[2][misorientation_mask],\n",
    "                                                                                    partials11,\n",
    "                                                                                    full11[idx12],\n",
    "                                                                                    common_partial=partials11[idx12])\n",
    "                                        \n",
    "                                        valid_conn[12].extend(scrub_repeats(valid_conn[12], full12))\n",
    "                                        \n",
    "                                        if len(partials12) < 2:\n",
    "                                            continue\n",
    "                                        \n",
    "                                        raise RuntimeError('Currently no supported connections greater than 12!')\n",
    "    rem_pair_mask[i] = False \n",
    "    #break         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spot_qs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Decompose connections\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Based on minimum of most connected structure (could do most connected -1)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_orientation_index\u001b[39m(connection,\n\u001b[1;32m----> 5\u001b[0m                           spot_qs\u001b[38;5;241m=\u001b[39m\u001b[43mspot_qs\u001b[49m,\n\u001b[0;32m      6\u001b[0m                           ref_qs\u001b[38;5;241m=\u001b[39mref_qs):\n\u001b[0;32m      7\u001b[0m     fit_spot_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnonzero(\u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misnan(connection))\n\u001b[0;32m      8\u001b[0m     fit_spot_qs \u001b[38;5;241m=\u001b[39m spot_qs[fit_spot_indices]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spot_qs' is not defined"
     ]
    }
   ],
   "source": [
    "# Decompose connections\n",
    "# Based on minimum of most connected structure (could do most connected -1)\n",
    "\n",
    "def fit_orientation_index(connection,\n",
    "                          spot_qs,\n",
    "                          ref_qs):\n",
    "    fit_spot_indices = np.nonzero(~np.isnan(connection))\n",
    "    fit_spot_qs = spot_qs[fit_spot_indices]\n",
    "\n",
    "    fit_ref_indices = connection[fit_spot_indices].astype(int)\n",
    "    # fit_ref_hkls = np.asarray(ref_hkls)[fit_ref_indices]\n",
    "    fit_ref_qs = np.asarray(ref_qs)[fit_ref_indices]\n",
    "\n",
    "    fit_orientation, fit_rssd = Rotation.align_vectors(fit_ref_qs, fit_spot_qs)\n",
    "\n",
    "    fit_euclidean_errors = [np.sqrt(np.sum([(p - q)**2 for p, q in zip(v1, v2)]))\n",
    "                            for v1, v2 in zip(fit_ref_qs, fit_orientation.apply(fit_spot_qs, inverse=False))]\n",
    "    rmse = np.mean(fit_euclidean_errors)\n",
    "\n",
    "    return fit_orientation, rmse\n",
    "\n",
    "def check_collinearity(connection_pair, ref_hkls):\n",
    "    pair_ref_hkls = [ref_hkls[int(ind)] for ind\n",
    "                    in connection_pair[~np.isnan(connection_pair)]]\n",
    "\n",
    "    # Check for colinearity; 3D orientation cannot be determined\n",
    "    pair_divs = np.array(pair_ref_hkls[0]) / np.array(pair_ref_hkls[1])\n",
    "    return len(np.unique(pair_divs[~np.isnan(pair_divs)])) < 2\n",
    "\n",
    "\n",
    "mutable_conn = dict(zip(\n",
    "    valid_conn.keys(),\n",
    "    [value.copy() for value in valid_conn.values()]    \n",
    "))\n",
    "\n",
    "excluded_spot_indices = []\n",
    "best_connections = []\n",
    "best_orientations = []\n",
    "best_errors = []\n",
    "DECOMPOSING_PATTERN = True\n",
    "while DECOMPOSING_PATTERN:\n",
    "    # Remove unused connections\n",
    "    del_keys = []\n",
    "    for key, value in mutable_conn.items():\n",
    "        mutable_conn[key] = np.asarray(value)\n",
    "        if len(value) == 0:\n",
    "            del_keys.append(key)\n",
    "    for key in del_keys:\n",
    "        del mutable_conn[key]\n",
    "\n",
    "    # Find best connected rank\n",
    "    largest_key = np.max([key for key, value in mutable_conn.items() if len(value) > 0])\n",
    "    largest_connections = mutable_conn[largest_key]\n",
    "\n",
    "    # Find best bit orientation\n",
    "    fit_orientations = []\n",
    "    fit_rmse = []\n",
    "    print(f'Searching for best fit rank {largest_key} connection out of {len(largest_connections)} possibilities.')\n",
    "    for connection in largest_connections:\n",
    "        if largest_key == 2:\n",
    "            if check_collinearity(connection, ref_hkls):\n",
    "                continue\n",
    "\n",
    "        fit_orientation, rmse = fit_orientation_index(connection)    \n",
    "        fit_orientations.append(fit_orientation)\n",
    "        fit_rmse.append(rmse)\n",
    "    \n",
    "    if len(fit_orientations) < 1:\n",
    "        DECOMPOSING_PATTERN = False\n",
    "\n",
    "    best_connections.append(largest_connections[np.argmin(fit_rmse)])\n",
    "    best_orientations.append(fit_orientations[np.argmin(fit_rmse)])\n",
    "    best_errors.append(fit_rmse[np.argmin(fit_rmse)])\n",
    "    fit_spot_indices = np.nonzero(~np.isnan(largest_connections[np.argmin(fit_rmse)]))[0]\n",
    "    excluded_spot_indices.extend(fit_spot_indices)\n",
    "\n",
    "    # Scrub all excluded_spot_indices from remaining connections\n",
    "    conn_masks = []\n",
    "    for key, connections in mutable_conn.items():\n",
    "        conn_mask = [True,] * len(connections)\n",
    "        for idx, connection in enumerate(connections):\n",
    "            conn_mask[idx] = np.all([index not in np.nonzero(~np.isnan(connection))[0]\n",
    "                                    for index in excluded_spot_indices])\n",
    "        mutable_conn[key] = connections[conn_mask]\n",
    "\n",
    "    if len(mutable_conn[2]) < 1:\n",
    "        DECOMPOSING_PATTERN = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection':'3d'})\n",
    "\n",
    "\n",
    "colors = ['k',] * len(best_connections)\n",
    "colors = ['black', 'blue', 'green', 'purple'] + ['none'] * (len(best_connections) - 4)\n",
    "\n",
    "for best_fit_ind in range(len(best_connections)):\n",
    "    if best_fit_ind > 0:\n",
    "        break\n",
    "\n",
    "    if np.sum(~np.isnan(best_connections[best_fit_ind])) < 3:\n",
    "        continue\n",
    "\n",
    "    rot_qs = ref_qs @ best_orientations[best_fit_ind].as_matrix()\n",
    "    q_mask = np.all([\n",
    "        np.all([rot_qs[:, 0] > q_mins[0], rot_qs[:, 0] < q_maxs[0]], axis=0),\n",
    "        np.all([rot_qs[:, 1] > q_mins[1], rot_qs[:, 1] < q_maxs[1]], axis=0),\n",
    "        np.all([rot_qs[:, 2] > q_mins[2], rot_qs[:, 2] < q_maxs[2]], axis=0),\n",
    "    ], axis=0)\n",
    "    ax.scatter(*rot_qs[q_mask].T, s=ref_fs[q_mask] * 0.1, c=colors[best_fit_ind])\n",
    "\n",
    "    hkls = [ref_hkls[int(ind)] for ind in best_connections[best_fit_ind][~np.isnan(best_connections[best_fit_ind])]]\n",
    "    fit_spots = spot_qs[np.nonzero(~np.isnan(best_connections[best_fit_ind]))[0]]\n",
    "    for idx, hkl in enumerate(hkls):\n",
    "        ax.text(*fit_spots[idx], str(hkl), fontsize=8, c=colors[best_fit_ind])\n",
    "\n",
    "\n",
    "ax.scatter(*np.asarray(spot_qs).T, s = 1, c='r')\n",
    "ax.set_xlim(q_mins[0], q_maxs[0])\n",
    "ax.set_ylim(q_mins[1], q_maxs[1])\n",
    "ax.set_zlim(q_mins[2], q_maxs[2])\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection':'3d'})\n",
    "\n",
    "best_fit_ind = 0\n",
    "\n",
    "rot_qs = ref_qs @ best_orientations[best_fit_ind].as_matrix()\n",
    "q_mask = np.all([\n",
    "    np.all([rot_qs[:, 0] > q_mins[0], rot_qs[:, 0] < q_maxs[0]], axis=0),\n",
    "    np.all([rot_qs[:, 1] > q_mins[1], rot_qs[:, 1] < q_maxs[1]], axis=0),\n",
    "    np.all([rot_qs[:, 2] > q_mins[2], rot_qs[:, 2] < q_maxs[2]], axis=0),\n",
    "], axis=0)\n",
    "ax.scatter(*rot_qs[q_mask].T, s=ref_fs[q_mask] * 0.1, c='k')\n",
    "\n",
    "hkls = [ref_hkls[int(ind)] for ind in best_connections[best_fit_ind][~np.isnan(best_connections[best_fit_ind])]]\n",
    "fit_spots = spot_qs[np.nonzero(~np.isnan(best_connections[best_fit_ind]))[0]]\n",
    "for idx, hkl in enumerate(hkls):\n",
    "    ax.text(*fit_spots[idx], str(hkl), fontsize=8)\n",
    "\n",
    "\n",
    "best_fit_ind = 1\n",
    "\n",
    "rot_qs = ref_qs @ best_orientations[best_fit_ind].as_matrix()\n",
    "q_mask = np.all([\n",
    "    np.all([rot_qs[:, 0] > q_mins[0], rot_qs[:, 0] < q_maxs[0]], axis=0),\n",
    "    np.all([rot_qs[:, 1] > q_mins[1], rot_qs[:, 1] < q_maxs[1]], axis=0),\n",
    "    np.all([rot_qs[:, 2] > q_mins[2], rot_qs[:, 2] < q_maxs[2]], axis=0),\n",
    "], axis=0)\n",
    "ax.scatter(*rot_qs[q_mask].T, s=ref_fs[q_mask] * 0.1, c='blue')\n",
    "\n",
    "hkls = [ref_hkls[int(ind)] for ind in best_connections[best_fit_ind][~np.isnan(best_connections[best_fit_ind])]]\n",
    "fit_spots = spot_qs[np.nonzero(~np.isnan(best_connections[best_fit_ind]))[0]]\n",
    "for idx, hkl in enumerate(hkls):\n",
    "    ax.text(*fit_spots[idx], str(hkl), fontsize=8, c='blue')\n",
    "\n",
    "\n",
    "best_fit_ind = 2\n",
    "\n",
    "rot_qs = ref_qs @ best_orientations[best_fit_ind].as_matrix()\n",
    "q_mask = np.all([\n",
    "    np.all([rot_qs[:, 0] > q_mins[0], rot_qs[:, 0] < q_maxs[0]], axis=0),\n",
    "    np.all([rot_qs[:, 1] > q_mins[1], rot_qs[:, 1] < q_maxs[1]], axis=0),\n",
    "    np.all([rot_qs[:, 2] > q_mins[2], rot_qs[:, 2] < q_maxs[2]], axis=0),\n",
    "], axis=0)\n",
    "ax.scatter(*rot_qs[q_mask].T, s=ref_fs[q_mask] * 0.1, c='green')\n",
    "\n",
    "hkls = [ref_hkls[int(ind)] for ind in best_connections[best_fit_ind][~np.isnan(best_connections[best_fit_ind])]]\n",
    "fit_spots = spot_qs[np.nonzero(~np.isnan(best_connections[best_fit_ind]))[0]]\n",
    "for idx, hkl in enumerate(hkls):\n",
    "    ax.text(*fit_spots[idx], str(hkl), fontsize=8, c='green')\n",
    "\n",
    "\n",
    "ax.scatter(*np.asarray(spot_qs).T, s = 1, c='r')\n",
    "ax.set_xlim(q_mins[0], q_maxs[0])\n",
    "ax.set_ylim(q_mins[1], q_maxs[1])\n",
    "ax.set_zlim(q_mins[2], q_maxs[2])\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for best fit connection out of 12 of rank 9 connections.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04530987972079391,\n",
       " 0.03632377315726579,\n",
       " 0.04530987972079413,\n",
       " 0.036323773157265773,\n",
       " 0.045309879720794394,\n",
       " 0.036323773157265746,\n",
       " 0.04530987972079405,\n",
       " 0.03632377315726581,\n",
       " 0.04560220177884898,\n",
       " 0.045602201778849105,\n",
       " 0.045602201778849105,\n",
       " 0.045602201778848994]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_key = np.max([key for key, value in valid_conn.items() if len(value) > 0])\n",
    "largest_connections = valid_conn[largest_key]\n",
    "\n",
    "print(f'Searching for best fit connection out of {len(largest_connections)} of rank {largest_key} connections.')\n",
    "fit_orientations = []\n",
    "fit_mean_errors = []\n",
    "fit_ref_all_hkls = []\n",
    "fit_all_spots = []\n",
    "for connection in largest_connections:\n",
    "\n",
    "    #connection = valid_octets[0]\n",
    "\n",
    "    fit_spot_indices = np.nonzero(~np.isnan(connection))\n",
    "    fit_spot_qs = spot_qs[fit_spot_indices]\n",
    "    fit_all_spots.append(fit_spot_qs)\n",
    "\n",
    "    fit_ref_indices = connection[fit_spot_indices].astype(int)\n",
    "    fit_ref_hkls = np.asarray(ref_hkls)[fit_ref_indices]\n",
    "    fit_ref_all_hkls.append(fit_ref_hkls)\n",
    "    fit_ref_qs = np.asarray(ref_qs)[fit_ref_indices]\n",
    "\n",
    "    fit_orientation, fit_rssd = Rotation.align_vectors(fit_ref_qs, fit_spot_qs)\n",
    "\n",
    "    fit_euclidean_error = [np.sqrt(np.sum([(p - q)**2 for p, q in zip(v1, v2)]))\n",
    "                        for v1, v2 in zip(fit_ref_qs, fit_orientation.apply(fit_spot_qs, inverse=False))]\n",
    "    mean_euclidean_error = np.mean(fit_euclidean_error)\n",
    "\n",
    "    fit_orientations.append(fit_orientation)\n",
    "    fit_mean_errors.append(mean_euclidean_error)\n",
    "fit_mean_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=200, subplot_kw={'projection':'3d'})\n",
    "\n",
    "min_ind = np.argmin(fit_mean_errors)\n",
    "min_ind = 8\n",
    "\n",
    "ax.scatter(*np.asarray(spot_qs).T, s = 1, c='r')\n",
    "\n",
    "rot_qs = ref_qs @ fit_orientations[min_ind].as_matrix()\n",
    "q_mask = np.all([\n",
    "    np.all([rot_qs[:, 0] > q_mins[0], rot_qs[:, 0] < q_maxs[0]], axis=0),\n",
    "    np.all([rot_qs[:, 1] > q_mins[1], rot_qs[:, 1] < q_maxs[1]], axis=0),\n",
    "    np.all([rot_qs[:, 2] > q_mins[2], rot_qs[:, 2] < q_maxs[2]], axis=0),\n",
    "], axis=0)\n",
    "\n",
    "ax.scatter(*rot_qs[q_mask].T, s=ref_fs[q_mask] * 0.1, c='k')\n",
    "\n",
    "for idx, hkl in enumerate(fit_ref_all_hkls[min_ind]):\n",
    "    ax.text(*fit_all_spots[min_ind][idx], str(hkl), fontsize=8)\n",
    "\n",
    "ax.set_xlim(q_mins[0], q_maxs[0])\n",
    "ax.set_ylim(q_mins[1], q_maxs[1])\n",
    "ax.set_zlim(q_mins[2], q_maxs[2])\n",
    "\n",
    "ax.set_xlabel('qx [Å⁻¹]')\n",
    "ax.set_ylabel('qy [Å⁻¹]')\n",
    "ax.set_zlabel('qz [Å⁻¹]')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_collinear(vectors):\n",
    "    vecs = np.asarray(vectors)\n",
    "    collinear_flag = True\n",
    "\n",
    "    # Probably faster. Not easy to perform pairwise\n",
    "    if len(vecs) == 2:\n",
    "        if np.sum(np.abs(np.cross(*vecs))) > 1e-8:\n",
    "            collinear_flag = False\n",
    "        return collinear_flag\n",
    "\n",
    "    # Pairwise analysis fo list of vectors\n",
    "    const_list = []\n",
    "    for ind in range(vecs.shape[1]):\n",
    "        vecs_axis = vecs[:, ind]\n",
    "        if not np.any(vecs_axis == 0):\n",
    "            const = np.abs(vecs_axis[:, np.newaxis] / vecs_axis[np.newaxis, :])\n",
    "            const_list.append(np.round(const, 3))\n",
    "\n",
    "    combos = list(combinations(range(vecs.shape[1]), 2))\n",
    "    if len(combos) > 1:\n",
    "        combos.pop(-1) # last index is redundant\n",
    "\n",
    "    for combo in combos:\n",
    "        if np.any(const_list[combo[0]] != const_list[combo[1]]):\n",
    "            collinear_flag = False\n",
    "            break\n",
    "        \n",
    "    return collinear_flag\n",
    "\n",
    "\n",
    "def vector_angle(v1, v2, degrees=False):\n",
    "    angle = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1, axis=-1) *  np.linalg.norm(v2, axis=-1)))\n",
    "    if degrees:\n",
    "        angle = np.degrees(angle)\n",
    "    return angle\n",
    "\n",
    "\n",
    "def multi_vector_angles(v1s, v2s, degrees=False):\n",
    "    v1_units = v1s / np.linalg.norm(v1s, axis=1).reshape(-1, 1)\n",
    "    v2_units = v2s / np.linalg.norm(v2s, axis=1).reshape(-1, 1)\n",
    "    angles = np.arccos(np.inner(v1_units, v2_units).round(6)) # Not happy about the round...\n",
    "    if degrees:\n",
    "        angles = np.degrees(angles)\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pair_voting_indexing(spot_qs,\n",
    "                         spot_ints,\n",
    "                         phase,\n",
    "                         near_q=0.005,\n",
    "                         near_angle=5):\n",
    "\n",
    "    spot_q_mags = np.linalg.norm(spot_qs, axis=1)\n",
    "    max_q = np.max(spot_q_mags)\n",
    "\n",
    "    # Combine these at some point...\n",
    "    stibnite.get_hkl_reflections()\n",
    "    ref_hkls, ref_qs, ref_fs = generate_reciprocal_lattice(stibnite, 1.15 * max_q) # 15% window\n",
    "    ref_q_mags = np.linalg.norm(ref_qs, axis=1)\n",
    "\n",
    "    # Minimum step size in q-space.\n",
    "    min_q = np.min(np.linalg.norm(phase.Q([[1, 0, 0], [0, 1, 0], [0, 0, 1]]), axis=0))\n",
    "\n",
    "    # Find difference between measured and calculated q magnitudes\n",
    "    diff_arr = np.abs(spot_q_mags[:, np.newaxis]\n",
    "                    - ref_q_mags[np.newaxis, :])\n",
    "\n",
    "    # Eliminate any reflections outside phase-allowed spots\n",
    "    phase_mask = np.any(diff_arr < near_q, axis=1)\n",
    "    diff_arr = diff_arr[phase_mask]\n",
    "    spot_qs = spot_qs[phase_mask]\n",
    "    spot_q_mags = spot_q_mags[phase_mask]\n",
    "    spot_ints = spot_ints[phase_mask]\n",
    "\n",
    "    # Generate all pairs of spots which are crystallographically feasible\n",
    "    spot_pair_indices = list(combinations(range(len(spot_qs)), 2))\n",
    "    spot_diff_arr = np.abs(spot_q_mags[:, np.newaxis]\n",
    "                        - spot_q_mags[np.newaxis, :])\n",
    "    allowed_pairs = [spot_diff_arr[indices] > min_q * 0.85 for indices in spot_pair_indices]\n",
    "    spot_pair_indices = np.asarray(spot_pair_indices)[allowed_pairs]\n",
    "\n",
    "    # Compute all angles\n",
    "    spot_angles = multi_vector_angles(spot_qs, spot_qs, degrees=True)\n",
    "    ref_angles = multi_vector_angles(ref_qs, ref_qs, degrees=True)\n",
    "\n",
    "    votes = [[] for _ in range(len(spot_qs))]\n",
    "\n",
    "    for pair in spot_pair_indices:\n",
    "        ref_combos = list(product(*[np.nonzero(diff_arr[i] < near_q)[0] for i in pair]))\n",
    "        angle_mask = [np.abs(spot_angles[tuple(pair)] - ref_angles[tuple(combo)]) < near_angle for combo in ref_combos]\n",
    "        for ref_vote in np.asarray(ref_combos)[angle_mask]:\n",
    "            votes[pair[0]].append(ref_vote[0])\n",
    "            votes[pair[1]].append(ref_vote[1])\n",
    "\n",
    "    guess_refl = [None,] * len(spot_qs)\n",
    "\n",
    "    for i, vote in enumerate(votes):\n",
    "        spot_inds = np.unique(vote)\n",
    "        spot_votes = [np.sum(vote == ind) for ind in spot_inds]\n",
    "        sorted_votes = sorted(spot_votes, reverse=True)\n",
    "        sorted_ind = [x for x, _ in sorted(zip(spot_inds, spot_votes),\n",
    "                                        key=lambda pair: pair[0])]\n",
    "\n",
    "        guess_refl[i] = dict(zip(sorted_ind, sorted_votes))\n",
    "\n",
    "    return guess_refl, spot_qs, ref_hkls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
